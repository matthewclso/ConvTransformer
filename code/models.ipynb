{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fPMU4Lwy4MDd"
   },
   "outputs": [],
   "source": [
    "# Limits for how many words can be considered\n",
    "zh_vocab_size = 30000\n",
    "en_vocab_size = 30000\n",
    "\n",
    "# Limits for how long a sequence will be considered\n",
    "zh_max_len = 200\n",
    "en_max_len = 200\n",
    "\n",
    "# Limits for how much of the dataset to load\n",
    "train_samples = 300000\n",
    "val_samples = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "import numpy as np\n",
    "import h5py\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import functools\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = os.getcwd()\n",
    "os.chdir(\"/ibex/scratch/somc\")\n",
    "\n",
    "with h5py.File(\"zh_train_ds.hdf5\", \"r\") as f:\n",
    "  zh_train_ds = f[\"zh_train_ds\"][:]\n",
    "with h5py.File(\"en_train_ds.hdf5\", \"r\") as f:\n",
    "  en_train_ds = f[\"en_train_ds\"][:]\n",
    "with h5py.File(\"zh_val_ds.hdf5\", \"r\") as f:\n",
    "  zh_val_ds = f[\"zh_val_ds\"][:]\n",
    "with h5py.File(\"en_val_ds.hdf5\", \"r\") as f:\n",
    "  en_val_ds = f[\"en_val_ds\"][:]\n",
    "zh_timesteps, en_timesteps = zh_train_ds.shape[1], en_train_ds.shape[1]\n",
    "training_samples, val_samples = zh_train_ds.shape[0], zh_val_ds.shape[0]\n",
    "print(f\"Chinese training dataset samples: {training_samples}   Chinese training dataset timesteps: {zh_timesteps}\")\n",
    "print(f\"English training dataset samples: {training_samples}   English training dataset timesteps: {en_timesteps}\")\n",
    "print(f\"Chinese validation dataset samples: {val_samples}   Chinese validation dataset timesteps: {zh_timesteps}\")\n",
    "print(f\"English validation dataset samples: {val_samples}   English validation dataset timesteps: {en_timesteps}\")\n",
    "\n",
    "zh_tokenize = tf.keras.models.load_model(\"zh_tokenize\")\n",
    "en_tokenize = tf.keras.models.load_model(\"en_tokenize\")\n",
    "\n",
    "zh_train_ds = zh_train_ds[0:train_samples]\n",
    "en_train_ds = en_train_ds[0:train_samples]\n",
    "zh_val_ds = zh_val_ds[0:val_samples]\n",
    "en_val_ds = en_val_ds[0:val_samples]\n",
    "\n",
    "en_dec_train_ds = np.concatenate((en_train_ds[:, 1:], np.zeros((en_train_ds.shape[0], 1))), axis = 1)\n",
    "en_dec_val_ds = np.concatenate((en_val_ds[:, 1:], np.zeros((en_val_ds.shape[0], 1))), axis = 1)\n",
    "\n",
    "os.chdir(work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of using separate validation set, use samples from train set instead\n",
    "zh_train_ds, zh_val_ds, en_train_ds, en_val_ds = train_test_split(zh_train_ds, en_train_ds, test_size = .03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "id": "VRE2Gar1M4_I",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x2b4843e6bfd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pcolormesh(zh_train_ds != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "collapsed": true,
    "id": "nEBoQvCqNeWO",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "9bc66018-e32b-4a4d-f177-c67c987f1537",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x7fa0e68d49d0>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAD4CAYAAAApWAtMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXAUlEQVR4nO3dbYxcV53n8e8/D2CGpyRkxjJ+WIcdMxIzknloJZFgRtnZJTgRO4bdUciwIg5EeFYQTdCw2jiANhGJRmF3yCg7ILNmEsVGgJMNoFijZBs7g5c34zhxSMgTDx5wlDaOPYk9SSRWzDr73xf3dLrc9EN11a2+VX2/H6lUt06dW3X6dvn8fM65tzoyE0mS+nFa0w2QJI0+w0SS1DfDRJLUN8NEktQ3w0SS1Lczmm5A3c495/Rcu/rMOev85Ie/sUitkaTR8BInnsvM3+x1/yUXJmtXn8n+8TUDf5/3vXn9wN9DkhbLnrz76X72X3JhUjdDQ5LmZ5hMY3hI0sIZJtOM/+LReesYOJJ0KsOkB90EznQGkKSlzDAZMENEUhsYJjUyOCS1lWEyjYEgSQtnmEzT7XqIoSNJUwyTHvWyCF8nw0zSMDFMamQHL6mtDJMFMCwkaWaGyTwMEEman2Eyj6bXRsBAkzT8DJMhYFhIGnWGSQMMD0lLjWEyCzt8Serekg4TA0GSFseSDpNBLp4bVJI05bSmGyBJGn1LemQySNNHPY5UJLWZYVITp9QktZlh0ic7ekkyTHpigEjSqQyTHtQ1pWUoSVoqDJMG1b3OYjhJaophMmQMBEmjyDCZhZ26JHVv3osWI2J1RHwvIp6MiCci4ppSfkNEHI6IR8rt0o59rouIgxHx44h4X0f5hlJ2MCK2dJSfFxEPlPI7I+JVpfzV5fHB8vzaOn94SVI9uhmZnAQ+nZkPR8TrgQMRsbs891eZ+ZedlSPibcDlwO8Cbwb2RMRby9NfBt4LTAAPRsSuzHwS+EJ5rZ0R8RXgKmBruT+Rmb8dEZeXeh/q5wfu1qCuG3HEI2kpmjdMMvMIcKRsvxQRTwEr59hlI7AzM38F/DwiDgLnl+cOZubPACJiJ7CxvN4fAh8udbYDN1CFycayDXA38KWIiMzMrn/CATAQJOlUC1ozKdNM7wAeAN4NXB0RVwAPUY1eTlAFzb6O3SaYCp9nppVfALwJ+KfMPDlD/ZWT+2TmyYh4odR/blq7NgObAdasHPwyULejFkNHUlt03fNGxOuAbwGfyswXI2IrcCOQ5f6LwMcG0sp5ZOY2YBvA2PpljY5aOvUzVWYQSRolXYVJRJxJFSRfz8xvA2Tm0Y7nvwr8bXl4GFjdsfuqUsYs5c8DZ0XEGWV00ll/8rUmIuIM4I2l/pJjeEgaZfOGSUQEcBvwVGbe0lG+oqynAHwQeLxs7wK+ERG3UC3ArwP2AwGsi4jzqELicuDDmZkR8T3gj4GdwCbgno7X2gT8fXn+7waxXmJHLkn96WZk8m7gI8BjEfFIKfsM8CcR8Xaqaa5DwJ8CZOYTEXEX8CTVmWCfzMyXASLiamAcOB24PTOfKK93LbAzIm4CfkAVXpT7r5VF/ONUAVS7uaajDBpJml80fGJU7cbWL8v942uabsZIMCglTdqTdx/IzLFe9/cK+AGys5bUFoZJnwwMSTJM+ta53mKwSGorw6RGg/zTvWBYSRpehsks7LglqXuGySwGPcrohoEmaVQYJkPA0JA06gyTRWZwSFqK5v3jWKrXMEyfSVLdHJn0yBGGJE0xTHrk18tL0hTDpE8GgyQZJn1zhCJJhkltDAZJbWaYdDAQJKk3hkkHT9s1UCX1xjBZQgwCSU0xTBaJHb2kpcww6ZMhIUmGSd9GcZ3FAJRUN8NkSNnhSxolhsmQmmnEY8BIGlaGSZ/s4CXJMJmVISFJ3TNMZuE0kyR1zzBZgF7O3DKAJLWBYYIdviT1yzDBa0UkqV/zhklErAZ2AMuBBLZl5q0RcQ5wJ7AWOARclpknIiKAW4FLgV8CV2bmw+W1NgGfKy99U2ZuL+XvAu4AXgPcC1yTmTnbe/T9Uy8iO31JbdDNyOQk8OnMfDgiXg8ciIjdwJXA/Zl5c0RsAbYA1wKXAOvK7QJgK3BBCYbrgTGqUDoQEbtKOGwFPg48QBUmG4D7ymvO9B4jY6GjHsNH0iiaN0wy8whwpGy/FBFPASuBjcBFpdp2YC9VR78R2JGZCeyLiLMiYkWpuzszjwOUQNoQEXuBN2TmvlK+A/gAVZjM9h6NsKOXpJktaM0kItYC76AaQSwvQQPwLNU0GFRB80zHbhOlbK7yiRnKmeM9prdrM7AZYM3KwS0DLfbaiuElaVR03fNGxOuAbwGfyswXq6WRSlnfyAG0r6v3yMxtwDaAsfXLem6Hnbck9aarMImIM6mC5OuZ+e1SfDQiVmTmkTKNdayUHwZWd+y+qpQdZmrKarJ8bylfNUP9ud5jILodeRg6knSqbs7mCuA24KnMvKXjqV3AJuDmcn9PR/nVEbGTagH+hRIG48BfRMTZpd7FwHWZeTwiXoyIC6mmz64A/nqe92jUQqa7DB5JbdDNyOTdwEeAxyLikVL2GaoO/q6IuAp4GrisPHcv1WnBB6lODf4oQAmNG4EHS73PTy7GA59g6tTg+8qNOd5jZEwPHsNF0lIU1UlXS8fY+mW5f3xN0814heEhaRTsybsPZOZYr/t7BXyNDA5JbWWYLIBhIUkzM0wWwKvZJWlmhkmNDA9JbWWY1MjrVCS1lWEyYAaHpDYwTAbMP/8rqQ0MkwbMNR1m0EgaRYbJLOzUJal7hsksXEyXpO4ZJn2aL3QMG0ltYJgMWDcjHANH0qgzTAbMoJDUBobJPAwDSZqfYTILQ0SSumeYzKJzrcNgkaS5GSbTGByStHCGyTReXyJJC2eY9Gihf9tkkiEkaSkyTAbI4JDUFobJAHl1vKS2MEwGyLCQ1BaGyQA5MpHUFobJNHbwkrRwhgkGiCT1yzCh99N8pzOUJLWVYYIhIEn9Mkzwe7gkqV/zhklE3A68HziWmb9Xym4APg78Y6n2mcy8tzx3HXAV8DLwZ5k5Xso3ALcCpwN/k5k3l/LzgJ3Am4ADwEcy858j4tXADuBdwPPAhzLzUA0/85zqmvJqgkEoqSndjEzuAL5E1bF3+qvM/MvOgoh4G3A58LvAm4E9EfHW8vSXgfcCE8CDEbErM58EvlBea2dEfIUqiLaW+xOZ+dsRcXmp96Eefsba2FlL0szmDZPM/H5ErO3y9TYCOzPzV8DPI+IgcH557mBm/gwgInYCGyPiKeAPgQ+XOtuBG6jCZGPZBrgb+FJERGZml22phQEiSfPrZ83k6oi4AngI+HRmngBWAvs66kyUMoBnppVfQDW19U+ZeXKG+isn98nMkxHxQqn/3PSGRMRmYDPAmpX1LgON4rSXAShpsfXa824FbgSy3H8R+FhdjVqozNwGbAMYW79sUUcuTTEwJA2TnsIkM49ObkfEV4G/LQ8PA6s7qq4qZcxS/jxwVkScUUYnnfUnX2siIs4A3ljqD5SdtCQtXE9hEhErMvNIefhB4PGyvQv4RkTcQrUAvw7YDwSwrpy5dZhqkf7DmZkR8T3gj6nO6NoE3NPxWpuAvy/P/91irJfUOa1lMElqi25ODf4mcBFwbkRMANcDF0XE26mmuQ4BfwqQmU9ExF3Ak8BJ4JOZ+XJ5nauBcapTg2/PzCfKW1wL7IyIm4AfALeV8tuAr5VF/ONUATQSDBFJbROLfHLUwI2tX5b7x9c03QzAUJE0Ovbk3Qcyc6zX/b0CfoDqPhPMcJI0rAyTHtmxS9IUw6RHc406DBpJbdPKMLGzl6R6tTJM+l3LMIwk6VStDJN++bfdJelUpzXdgKVo/BePjuR3eklSrwwTSVLfWjfN5RSUJNWvdWHihYSSVL/WhUnd2rI2YmhKmoth0sEOU5J6Y5h06GeUYRBJajPDpE+GiCQZJn3zO7okyTAZqLYszjfBoJaGy5IMEzsaSVpcSzJMRnFEYABKGmVLMkwWkyEgSYbJrAwJSeqeYTILz9KSpO4ZJj2YKWgMGEltZpgsgIEhSTMzTBZgoWeJGT6S2sIw6WDnL0m9aWWYGBqSVK9WhsmgL2o0rCS1TSvDZBAMEEltNm+YRMTtwPuBY5n5e6XsHOBOYC1wCLgsM09ERAC3ApcCvwSuzMyHyz6bgM+Vl70pM7eX8ncBdwCvAe4FrsnMnO09+v6JB6TJr3AxyCQ17bQu6twBbJhWtgW4PzPXAfeXxwCXAOvKbTOwFV4Jn+uBC4Dzgesj4uyyz1bg4x37bZjnPdTBIJE0DOYdmWTm9yNi7bTijcBFZXs7sBe4tpTvyMwE9kXEWRGxotTdnZnHASJiN7AhIvYCb8jMfaV8B/AB4L453mPJMRAkjbpe10yWZ+aRsv0ssLxsrwSe6ag3UcrmKp+YoXyu9xgKBoAkTelmmmtOZRSSNbSl5/eIiM0R8VBEPPSPz788yKZIkmbQ68jkaESsyMwjZRrrWCk/DKzuqLeqlB1maspqsnxvKV81Q/253uPXZOY2YBvA2PplAw22SV4NL0lTeh2Z7AI2le1NwD0d5VdE5ULghTJVNQ5cHBFnl4X3i4Hx8tyLEXFhORPsimmvNdN7jKTxXzz6yk2SlppuTg3+JtWo4tyImKA6K+tm4K6IuAp4GrisVL+X6rTgg1SnBn8UIDOPR8SNwIOl3ucnF+OBTzB1avB95cYc7zHyugkURzKSRklUyxFLx9j6Zbl/fE3TzRgYQ0bSIOzJuw9k5liv+3sF/ADZ8UtqC8OkRwaFJE0xTHrU1EK6ISZpGBkmI6aOEDOQJNXNMOmRHbIkTen7Cvg2Mkgk6VSOTLpgeEjS3ByZdMEr1yVpbo5MFmDYA8URlKSmGCYjzgCRNAwMkwYZBJKWCsOkQXVNmxlKkppmmNTITl1SWxkmNep1pGEISRp1rQsTO25Jql/rwmTYT++tm+EpaTG0LkwWys5YkubXyjAxICSpXq0Mk6Uw1WUgShomrQkTO19JGpzWhMmwj0YMO0mjrDVhspgMBklt41fQD4BfWS+pbRyZ1MTRiKQ2M0xqMgwjEQNNUlMMkxFiWEgaVq0OEztnSaqHC/CSpL61emQyDOscC+VoStIw6itMIuIQ8BLwMnAyM8ci4hzgTmAtcAi4LDNPREQAtwKXAr8ErszMh8vrbAI+V172pszcXsrfBdwBvAa4F7gmM7OfNi+Unbckza+Okcm/ysznOh5vAe7PzJsjYkt5fC1wCbCu3C4AtgIXlPC5HhgDEjgQEbsy80Sp83HgAaow2QDcV0Obu9bP6MUgktQWg5jm2ghcVLa3A3upwmQjsKOMLPZFxFkRsaLU3Z2ZxwEiYjewISL2Am/IzH2lfAfwAfoMEzt4Sapfv2GSwHcjIoH/kZnbgOWZeaQ8/yywvGyvBJ7p2HeilM1VPjFD+a+JiM3AZoA1K+f+kYZ9ncSwkzSK+g2T92Tm4Yj4LWB3RPyo88nMzBI0A1VCbBvA2Ppl876fHbYk1auvMMnMw+X+WER8BzgfOBoRKzLzSJnGOlaqHwZWd+y+qpQdZmpabLJ8bylfNUP9vg16dGJYSWqbnsMkIl4LnJaZL5Xti4HPA7uATcDN5f6esssu4OqI2Em1AP9CCZxx4C8i4uxS72Lgusw8HhEvRsSFVAvwVwB/3Wt7Z2KnL0n16Gdkshz4TnXGL2cA38jM/xURDwJ3RcRVwNPAZaX+vVSnBR+kOjX4owAlNG4EHiz1Pj+5GA98gqlTg++j5jO5uh2hGDqSNLdY5Ms2Bm5s/bLcP75m0d/XwJE0yvbk3Qcyc6zX/Vt9BXydHOVIajPDZBo7e0laOL/ocRr/SqIkLZwjkw6OSiSpN4ZJh6U4IjEgJS0Gw2RI2OlLGmWGSZ8MAUkyTBbE4JCkmbUuTAwESapf68JklBfZDUJJw6p1YTLKZgtCQ0ZS0wyTGtmpS2orw6RGozyFVgfDVGovw2RI2TFLGiWGSY/s7CVpimHSoyamtAwwScPKMOmBnbokncow6cFCRiUGj6Q2MEwGrM7pMINJ0rAyTHpgpy5JpzJMelD34rvhJGnUGSYDZlBIagPDZMBG+ap4g1BStwyTPtnhSlILw8TOX5Lq17ow6XbaydCRpO61Lky61dRahyEmaRQZJj2y05ekKUMfJhGxAbgVOB34m8y8ueEmAcN/lpZhJ2kxDXWYRMTpwJeB9wITwIMRsSszn2y2Zb2zk5e0FA11mADnAwcz82cAEbET2AiMbJj0M6IxiCQNq2EPk5XAMx2PJ4ALpleKiM3A5vLwV6ev+Onji9C2fp0LPLewXX46kIbMo4d2NmIU2jkKbQTbWbdRaefv9LPzsIdJVzJzG7ANICIeysyxhps0L9tZr1Fo5yi0EWxn3Uapnf3sf1pdDRmQw8DqjserSpkkaYgMe5g8CKyLiPMi4lXA5cCuhtskSZpmqKe5MvNkRFwNjFOdGnx7Zj4xz27bBt+yWtjOeo1CO0ehjWA769aKdkZm1tUQSVJLDfs0lyRpBBgmkqS+LZkwiYgNEfHjiDgYEVuabs+kiFgdEd+LiCcj4omIuKaU3xARhyPikXK7dAjaeigiHivteaiUnRMRuyPip+X+7Ibb+Dsdx+yRiHgxIj41DMczIm6PiGMR8XhH2YzHLyr/vXxefxgR72y4nf8tIn5U2vKdiDirlK+NiP/TcVy/0nA7Z/09R8R15Xj+OCLe12Ab7+xo36GIeKSUN3ksZ+uH6vt8ZubI36gW5/8BeAvwKuBR4G1Nt6u0bQXwzrL9euAnwNuAG4D/1HT7prX1EHDutLL/Cmwp21uALzTdzmm/92eBfzEMxxP4A+CdwOPzHT/gUuA+IIALgQcabufFwBll+wsd7VzbWW8IjueMv+fyb+pR4NXAeaU/OL2JNk57/ovAfxmCYzlbP1Tb53OpjExe+dqVzPxnYPJrVxqXmUcy8+Gy/RLwFNWV/aNiI7C9bG8HPtBgW6b718A/ZObTTTcEIDO/DxyfVjzb8dsI7MjKPuCsiFjRVDsz87uZebI83Ed1TVejZjmes9kI7MzMX2Xmz4GDVP3CQM3VxogI4DLgm4Nux3zm6Idq+3wulTCZ6WtXhq7Djoi1wDuAB0rR1WUIeXvT00dFAt+NiANRfUUNwPLMPFK2nwWWN9O0GV3Oqf9Qh+14wuzHb5g/sx+j+l/ppPMi4gcR8b8j4vebalSHmX7Pw3g8fx84mpmd34PU+LGc1g/V9vlcKmEy9CLidcC3gE9l5ovAVuBfAm8HjlANh5v2nsx8J3AJ8MmI+IPOJ7Ma/w7FueRRXcT6R8D/LEXDeDxPMUzHbzYR8VngJPD1UnQEWJOZ7wD+HPhGRLyhqfYxAr/nDn/Cqf/ZafxYztAPvaLfz+dSCZOh/tqViDiT6hf49cz8NkBmHs3MlzPz/wFfZRGG5PPJzMPl/hjwHao2HZ0c3pb7Y8218BSXAA9n5lEYzuNZzHb8hu4zGxFXAu8H/kPpWCjTRs+X7QNUaxFvbaqNc/yeh+p4RsQZwL8D7pwsa/pYztQPUePnc6mEydB+7UqZN70NeCozb+ko75x//CDQ6DcdR8RrI+L1k9tUC7KPUx3HTaXaJuCeZlr4a075X9+wHc8Osx2/XcAV5ayZC4EXOqYbFl1Uf4TuPwN/lJm/7Cj/zaj+rhAR8RZgHfCzZlo55+95F3B5RLw6Is6jauf+xW5fh38D/CgzJyYLmjyWs/VD1Pn5bOLMgkHcqM4++AlV2n+26fZ0tOs9VEPHHwKPlNulwNeAx0r5LmBFw+18C9XZMI8CT0weQ+BNwP1U33+/BzhnCI7pa4HngTd2lDV+PKnC7Qjwf6nmmK+a7fhRnSXz5fJ5fQwYa7idB6nmyCc/o18pdf99+Tw8AjwM/NuG2znr7xn4bDmePwYuaaqNpfwO4D9Oq9vksZytH6rt8+nXqUiS+rZUprkkSQ0yTCRJfTNMJEl9M0wkSX0zTCRJfTNMJEl9M0wkSX37/7xBI+KHZfpOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pcolormesh(en_train_ds != 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bHbZG5v0AGY",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Y_NXRCcjvjjY"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import jieba\n",
    "import urllib\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sa0Ep9Co0DnH"
   },
   "outputs": [],
   "source": [
    "config = tfds.translate.wmt.WmtConfig(\n",
    "    version = \"1.0.0\",\n",
    "    language_pair = (\"zh\", \"en\"),\n",
    "    subsets = {\n",
    "        tfds.Split.TRAIN: [\"newscommentary_v14\"],\n",
    "        tfds.Split.VALIDATION: [\"newstest2018\"],\n",
    "    },\n",
    ")\n",
    "builder = tfds.builder(\"wmt_translate\", config = config)\n",
    "builder.download_and_prepare()\n",
    "train_ds, val_ds = builder.as_dataset(split = [\"train\", \"validation\"], shuffle_files = True, as_supervised = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AdLiZ8ya8x3t",
    "outputId": "9771c3ee-caf5-474d-b2a1-913aa66ec53d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training dataset: 311556   Length of validation dataset: 3981\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of training dataset: {len(train_ds)}   Length of validation dataset: {len(val_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uj_pOP_Odix-"
   },
   "outputs": [],
   "source": [
    "with urllib.request.urlopen(\"https://raw.githubusercontent.com/fxsjy/jieba/master/jieba/dict.txt\") as f:\n",
    "  zh_dictionary = f.readlines()\n",
    "zh_dictionary = [x.decode(\"utf8\").split(\" \", 1)[0] for x in zh_dictionary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V41uRGay4pzT"
   },
   "outputs": [],
   "source": [
    "# Using 结巴 to tockenize Chinese text\n",
    "# The reason is because Chinese words cannot be delimited easily (as opposed to English with spaces), so we need a smarter library to split text into meaningful words.\n",
    "# For example, if 北 and 京 were processed as separate words, we would lose the meaning of 北京.  So we need a library to recognize these words.\n",
    "def get_zh_train_for_tok():\n",
    "  for i, (en, zh) in enumerate(train_ds):\n",
    "    cut = jieba.lcut(zh.numpy(), cut_all = False, HMM = True)\n",
    "    if cut[0] in zh_dictionary:  # Some samples have bad encoding, check here\n",
    "      zh_sentence = \" \".join(cut)\n",
    "      yield [\"<SOS> \" + zh_sentence + \" <EOS>\"]\n",
    "\n",
    "def get_en_train_for_tok():\n",
    "  for i, (en, zh) in enumerate(train_ds):\n",
    "    cut = jieba.lcut(zh.numpy(), cut_all = False, HMM = True)\n",
    "    if cut[0] in zh_dictionary:  # Some samples have bad encoding, check here\n",
    "      en_sentence = en.numpy().decode(\"utf8\")\n",
    "      yield [\"<SOS> \" + en_sentence + \" <EOS>\"]\n",
    "\n",
    "def get_zh_val_for_tok():\n",
    "  for i, (zh, en) in enumerate(val_ds):\n",
    "    cut = jieba.lcut(zh.numpy(), cut_all = False, HMM = True)\n",
    "    if cut[0] in zh_dictionary:  # Some samples have bad encoding, check here\n",
    "      zh_sentence = \" \".join(cut)\n",
    "      yield [\"<SOS> \" + zh_sentence + \" <EOS>\"]\n",
    "\n",
    "def get_en_val_for_tok():\n",
    "  for i, (zh, en) in enumerate(val_ds):\n",
    "    cut = jieba.lcut(zh.numpy(), cut_all = False, HMM = True)\n",
    "    if cut[0] in zh_dictionary:  # Some samples have bad encoding, check here\n",
    "      en_sentence = en.numpy().decode(\"utf8\")\n",
    "      yield [\"<SOS> \" + en_sentence + \" <EOS>\"]\n",
    "\n",
    "zh_train_tok_ds = tf.data.Dataset.from_generator(get_zh_train_for_tok, output_types = tf.string, output_shapes = (1,))\n",
    "en_train_tok_ds = tf.data.Dataset.from_generator(get_en_train_for_tok, output_types = tf.string, output_shapes = (1,))\n",
    "zh_val_tok_ds = tf.data.Dataset.from_generator(get_zh_val_for_tok, output_types = tf.string, output_shapes = (1,))\n",
    "en_val_tok_ds = tf.data.Dataset.from_generator(get_en_val_for_tok, output_types = tf.string, output_shapes = (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O3da-J2lx3Ek",
    "outputId": "2f13c5da-c861-4e9d-a09b-9b58d3139b7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Chinese sentence length: 199   Index of longest sentence: 104552\n",
      "Maximum English sentence length: 155   Index of longest sentence: 264333\n"
     ]
    }
   ],
   "source": [
    "zh_lens = [(str(x.numpy()).count(\" \") + 1) for x in zh_train_tok_ds]\n",
    "print(f\"Maximum Chinese sentence length: {max(zh_lens)}   Index of longest sentence: {zh_lens.index(max(zh_lens))}\")\n",
    "en_lens = [(str(x.numpy()).count(\" \") + 1) for x in en_train_tok_ds]\n",
    "print(f\"Maximum English sentence length: {max(en_lens)}   Index of longest sentence: {en_lens.index(max(en_lens))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QSWe2R5lqizJ"
   },
   "outputs": [],
   "source": [
    "# Define Chinese tokenizer\n",
    "zh_vectorize = tf.keras.layers.TextVectorization(\n",
    "    max_tokens = zh_vocab_size,\n",
    "    standardize = \"lower_and_strip_punctuation\",\n",
    "    split = \"whitespace\",\n",
    "    output_mode = \"int\",\n",
    "    output_sequence_length = zh_max_len)\n",
    "\n",
    "zh_vectorize.adapt(zh_train_tok_ds.prefetch(tf.data.AUTOTUNE), batch_size = 4096)\n",
    "zh_tokenize = tf.keras.models.Sequential()\n",
    "zh_tokenize.add(tf.keras.Input(shape = (1,), dtype = tf.string))\n",
    "zh_tokenize.add(zh_vectorize)\n",
    "\n",
    "# Define English tokenizer\n",
    "en_vectorize = tf.keras.layers.TextVectorization(\n",
    "    max_tokens = en_vocab_size,\n",
    "    standardize = \"lower_and_strip_punctuation\",\n",
    "    split = \"whitespace\",\n",
    "    output_mode = \"int\",\n",
    "    output_sequence_length = en_max_len)\n",
    "\n",
    "en_vectorize.adapt(en_train_tok_ds.prefetch(tf.data.AUTOTUNE), batch_size = 4096)\n",
    "en_tokenize = tf.keras.models.Sequential()\n",
    "en_tokenize.add(tf.keras.Input(shape = (1,), dtype = tf.string))\n",
    "en_tokenize.add(en_vectorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wii4SkczEfE5"
   },
   "outputs": [],
   "source": [
    "# Tokenize Chinese training dataset\n",
    "zh_tokenized = zh_tokenize.predict(zh_train_tok_ds.prefetch(tf.data.AUTOTUNE), batch_size = 4096)\n",
    "# Tokenize Chinese validation dataset\n",
    "zh_val_tokenized = zh_tokenize.predict(zh_val_tok_ds.prefetch(tf.data.AUTOTUNE), batch_size = 4096)\n",
    "\n",
    "# Tokenize English training dataset\n",
    "en_tokenized = en_tokenize.predict(en_train_tok_ds.prefetch(tf.data.AUTOTUNE), batch_size = 4096)\n",
    "# Tokenize English validation dataset\n",
    "en_val_tokenized = en_tokenize.predict(en_val_tok_ds.prefetch(tf.data.AUTOTUNE), batch_size = 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QyyX50B_Wo6f"
   },
   "outputs": [],
   "source": [
    "# Save tokenization layers for later use\n",
    "zh_tokenize.save(\"zh_tokenize\")\n",
    "en_tokenize.save(\"en_tokenize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JYzKvMMmy_ut"
   },
   "outputs": [],
   "source": [
    "def save_dataset(tokenized, filename):\n",
    "  tokenized = np.array(tokenized)\n",
    "  samples = tokenized.shape[0]\n",
    "  timesteps = tokenized.shape[1]\n",
    "  print(f\"Samples: {samples}   Timesteps: {timesteps}\")\n",
    "  with h5py.File(filename, \"w\") as f:\n",
    "    f.create_dataset(filename.split(\".\")[0], data = tokenized)\n",
    "\n",
    "save_dataset(zh_tokenized, \"zh_train_ds.hdf5\")\n",
    "save_dataset(en_tokenized, \"en_train_ds.hdf5\")\n",
    "save_dataset(zh_val_tokenized, \"zh_val_ds.hdf5\")\n",
    "save_dataset(en_val_tokenized, \"en_val_ds.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8Z1ZmKR0E1T",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# **LSTM RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 512\n",
    "embed_units = 512\n",
    "epochs = 50\n",
    "batch_size = 1024\n",
    "target_acc = .9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "iRd7VrRryTHv"
   },
   "outputs": [],
   "source": [
    "class LSTMEncoderCell(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, units):\n",
    "    super(LSTMEncoderCell, self).__init__()\n",
    "    self.units = units\n",
    "    self.state_size = (units, units)\n",
    "    self.output_size = units\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.w_update_x = self.add_weight(shape = (input_shape[-1], self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.w_update_h = self.add_weight(shape = (self.units, self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.b_update = self.add_weight(shape = (self.units,), initializer = \"random_normal\", trainable = True)\n",
    "\n",
    "    self.w_forget_x = self.add_weight(shape = (input_shape[-1], self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.w_forget_h = self.add_weight(shape = (self.units, self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.b_forget = self.add_weight(shape = (self.units,), initializer = \"random_normal\", trainable = True)\n",
    "\n",
    "    self.w_candidate_x = self.add_weight(shape = (input_shape[-1], self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.w_candidate_h = self.add_weight(shape = (self.units, self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.b_candidate = self.add_weight(shape = (self.units,), initializer = \"random_normal\", trainable = True)\n",
    "\n",
    "    self.w_activation_x = self.add_weight(shape = (input_shape[-1], self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.w_activation_h = self.add_weight(shape = (self.units, self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.b_activation = self.add_weight(shape = (self.units,), initializer = \"random_normal\", trainable = True)\n",
    "\n",
    "    self.built = True\n",
    "\n",
    "  def call(self, inputs, states):\n",
    "    prev_h = states[0]\n",
    "    prev_c = states[1]\n",
    "\n",
    "    update = tf.matmul(inputs, self.w_update_x)\n",
    "    update += tf.matmul(prev_h, self.w_update_h)\n",
    "    update += self.b_update\n",
    "    update = tf.keras.activations.sigmoid(update)\n",
    "\n",
    "    forget = tf.matmul(inputs, self.w_forget_x)\n",
    "    forget += tf.matmul(prev_h, self.w_forget_h)\n",
    "    forget += self.b_forget\n",
    "    forget = tf.keras.activations.sigmoid(forget)\n",
    "\n",
    "    candidate = tf.matmul(inputs, self.w_candidate_x)\n",
    "    candidate += tf.matmul(prev_h, self.w_candidate_h)\n",
    "    candidate += self.b_candidate\n",
    "    candidate = tf.keras.activations.sigmoid(candidate)\n",
    "\n",
    "    activation = tf.matmul(inputs, self.w_activation_x)\n",
    "    activation += tf.matmul(prev_h, self.w_activation_h)\n",
    "    activation += self.b_activation\n",
    "    activation = tf.keras.activations.sigmoid(activation)\n",
    "\n",
    "    c = tf.math.multiply(update, candidate) + tf.math.multiply(forget, prev_c)\n",
    "    h = tf.math.multiply(activation, tf.keras.activations.sigmoid(c))\n",
    "    \n",
    "    return h, [h, c]\n",
    "\n",
    "class LSTMManyInputDecoderCell(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, units, vocab_size):\n",
    "    super(LSTMManyInputDecoderCell, self).__init__()\n",
    "    self.units = units\n",
    "    self.state_size = (units, units)\n",
    "    self.output_size = units\n",
    "    self.vocab_size = vocab_size\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.w_update_x = self.add_weight(shape = (input_shape[-1], self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.w_update_h = self.add_weight(shape = (self.units, self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.b_update = self.add_weight(shape = (self.units,), initializer = \"random_normal\", trainable = True)\n",
    "\n",
    "    self.w_forget_x = self.add_weight(shape = (input_shape[-1], self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.w_forget_h = self.add_weight(shape = (self.units, self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.b_forget = self.add_weight(shape = (self.units,), initializer = \"random_normal\", trainable = True)\n",
    "\n",
    "    self.w_candidate_x = self.add_weight(shape = (input_shape[-1], self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.w_candidate_h = self.add_weight(shape = (self.units, self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.b_candidate = self.add_weight(shape = (self.units,), initializer = \"random_normal\", trainable = True)\n",
    "\n",
    "    self.w_activation_x = self.add_weight(shape = (input_shape[-1], self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.w_activation_h = self.add_weight(shape = (self.units, self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.b_activation = self.add_weight(shape = (self.units,), initializer = \"random_normal\", trainable = True)\n",
    "\n",
    "    self.w_softmax = self.add_weight(shape = (self.units, self.vocab_size), initializer = \"random_normal\", trainable = True)\n",
    "    self.b_softmax = self.add_weight(shape = (self.vocab_size,), initializer = \"random_normal\", trainable = True)\n",
    "\n",
    "    self.built = True\n",
    "\n",
    "  def call(self, inputs, states):\n",
    "    prev_h = states[0]\n",
    "    prev_c = states[1]\n",
    "\n",
    "    update = tf.matmul(inputs, self.w_update_x)\n",
    "    update += tf.matmul(prev_h, self.w_update_h)\n",
    "    update += self.b_update\n",
    "    update = tf.keras.activations.sigmoid(update)\n",
    "\n",
    "    forget = tf.matmul(inputs, self.w_forget_x)\n",
    "    forget += tf.matmul(prev_h, self.w_forget_h)\n",
    "    forget += self.b_forget\n",
    "    forget = tf.keras.activations.sigmoid(forget)\n",
    "\n",
    "    candidate = tf.matmul(inputs, self.w_candidate_x)\n",
    "    candidate += tf.matmul(prev_h, self.w_candidate_h)\n",
    "    candidate += self.b_candidate\n",
    "    candidate = tf.keras.activations.sigmoid(candidate)\n",
    "\n",
    "    activation = tf.matmul(inputs, self.w_activation_x)\n",
    "    activation += tf.matmul(prev_h, self.w_activation_h)\n",
    "    activation += self.b_activation\n",
    "    activation = tf.keras.activations.sigmoid(activation)\n",
    "\n",
    "    c = tf.math.multiply(update, candidate) + tf.math.multiply(forget, prev_c)\n",
    "    h = tf.math.multiply(activation, tf.keras.activations.sigmoid(c))\n",
    "\n",
    "    y = tf.matmul(h, self.w_softmax)\n",
    "    y += self.b_softmax\n",
    "    y = tf.keras.activations.softmax(y)\n",
    "    \n",
    "    return y, [h, c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQYLv09IoH9K"
   },
   "source": [
    "**Direct Sequence-to-Sequence Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GGYUdI1xOeB6",
    "outputId": "2f8b5856-fefa-412f-b20e-a5c905d89d1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 200)]             0         \n",
      "                                                                 \n",
      " embedding_6 (Embedding)     (None, 200, 512)          15360000  \n",
      "                                                                 \n",
      " rnn_6 (RNN)                 (None, 200, 512)          2099200   \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 200, 30000)       15390000  \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,849,200\n",
      "Trainable params: 32,849,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape = (zh_timesteps))\n",
    "x = tf.keras.layers.Embedding(zh_vocab_size, embed_units, input_length = zh_timesteps, mask_zero = True)(inputs)\n",
    "h = tf.keras.layers.RNN(LSTMEncoderCell(units), return_sequences = True)(x)\n",
    "y = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(en_vocab_size, activation = \"softmax\"))(h)\n",
    "model = tf.keras.Model(inputs = inputs, outputs = y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "roUUQVaFoWtS"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate = .01)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "model.compile(optimizer = optimizer, loss = loss, metrics = [\"accuracy\"])\n",
    "history = model.fit(zh_train_ds, en_train_ds, batch_size = batch_size, epochs = epochs, validation_data = (zh_val_ds, en_val_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYiqfHc5oN7M"
   },
   "source": [
    "**Encoder-Decoder Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3aDo4PyEaKNN",
    "outputId": "db31dc36-f51e-421e-bf56-fab6196cd5e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_12 (InputLayer)          [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " input_13 (InputLayer)          [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_11 (Embedding)       (None, 200, 512)     15360000    ['input_12[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_12 (Embedding)       (None, 200, 512)     15360000    ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " rnn_11 (RNN)                   [(None, 512),        2099200     ['embedding_11[0][0]']           \n",
      "                                 (None, 512),                                                     \n",
      "                                 (None, 512)]                                                     \n",
      "                                                                                                  \n",
      " rnn_12 (RNN)                   (None, 200, 30000)   17489200    ['embedding_12[0][0]',           \n",
      "                                                                  'rnn_11[0][1]',                 \n",
      "                                                                  'rnn_11[0][2]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 50,308,400\n",
      "Trainable params: 50,308,400\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs_encoder = tf.keras.Input(shape = (zh_timesteps))\n",
    "x = tf.keras.layers.Embedding(zh_vocab_size, embed_units, input_length = zh_timesteps, mask_zero = True)(inputs_encoder)\n",
    "h, h_s, c_s = tf.keras.layers.RNN(LSTMEncoderCell(units), return_state = True)(x)\n",
    "\n",
    "inputs_decoder = tf.keras.Input(shape = (en_timesteps))\n",
    "h = tf.keras.layers.Embedding(en_vocab_size, embed_units, input_length = en_timesteps, mask_zero = True)(inputs_decoder)\n",
    "y = tf.keras.layers.RNN(LSTMManyInputDecoderCell(units, en_vocab_size), return_sequences = True)(h, initial_state = [h_s, c_s])\n",
    "model = tf.keras.Model(inputs = [inputs_encoder, inputs_decoder], outputs = y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AJX75J-RIQFi"
   },
   "outputs": [],
   "source": [
    "class MaskedLoss(tf.keras.losses.Loss):\n",
    "  def __init__(self):\n",
    "    self.name = \"masked_loss\"\n",
    "    self.reduction = tf.keras.losses.Reduction.NONE\n",
    "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(reduction = self.reduction)\n",
    "\n",
    "  def __call__(self, y_true, y_pred, sample_weight):\n",
    "    loss = self.loss(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(y_true != 0, tf.float32)\n",
    "    loss *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss)\n",
    "\n",
    "class accuracy_callback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs = {}):\n",
    "    if(logs.get(\"accuracy\") >= target_acc):\n",
    "      self.model.stop_training = True\n",
    "\n",
    "acc_call = accuracy_callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jXmPnECQEr_B"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate = .01)\n",
    "loss = MaskedLoss()\n",
    "model.compile(optimizer = optimizer, loss = loss, metrics = [\"accuracy\"])\n",
    "history = model.fit([zh_train_ds, en_train_ds], en_dec_train_ds, batch_size = batch_size, epochs = epochs, callbacks = [acc_call])\n",
    "# history = model.fit([zh_train_ds, en_train_ds], en_train_ds, batch_size = 64, epochs = 50, validation_data = ([zh_val_ds, en_val_ds], en_dec_val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K0Um-x6PCT00"
   },
   "outputs": [],
   "source": [
    "# training on multiple GPUs\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "gpus = tf.config.list_logical_devices(\"GPU\")\n",
    "strategy = tf.distribute.MirroredStrategy(gpus)\n",
    "with strategy.scope():\n",
    "  inputs_encoder = tf.keras.Input(shape = (zh_timesteps))\n",
    "  x = tf.keras.layers.Embedding(zh_vocab_size, embed_units, input_length = zh_timesteps, mask_zero = True)(inputs_encoder)\n",
    "  h, h_s, c_s = tf.keras.layers.RNN(LSTMEncoderCell(units), return_state = True)(x)\n",
    "\n",
    "  inputs_decoder = tf.keras.Input(shape = (en_timesteps))\n",
    "  h = tf.keras.layers.Embedding(en_vocab_size, embed_units, input_length = en_timesteps, mask_zero = True)(inputs_decoder)\n",
    "  y = tf.keras.layers.RNN(LSTMManyInputDecoderCell(units, en_vocab_size), return_sequences = True)(h, initial_state = [h_s, c_s])\n",
    "  model = tf.keras.Model(inputs = [inputs_encoder, inputs_decoder], outputs = y)\n",
    "\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate = .01)\n",
    "  loss = MaskedLoss()\n",
    "  model.compile(optimizer = optimizer, loss = loss, metrics = [\"accuracy\"])\n",
    "  history = model.fit([zh_train_ds, en_train_ds], en_dec_train_ds, batch_size = batch_size, epochs = epochs, callbacks = [acc_call])\n",
    "  # history = model.fit([zh_train_ds, en_train_ds], en_train_ds, batch_size = 64, epochs = 50, validation_data = ([zh_val_ds, en_val_ds], en_dec_val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9d0mCYCid5CR"
   },
   "outputs": [],
   "source": [
    "loss = history.history[\"loss\"]\n",
    "accuracy = history.history[\"accuracy\"]\n",
    "# val_loss = history.history[\"val_loss\"]\n",
    "# val_accuracy = history.history[\"val_accuracy\"]\n",
    "timerange = range(len(loss))\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "loss_plot, = ax.plot(timerange, loss, color = \"blue\")\n",
    "loss_plot.set_label(\"Loss\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend(loc = \"upper left\")\n",
    "ax2 = ax.twinx()\n",
    "acc_plot, = ax2.plot(timerange, accuracy, color = \"purple\")\n",
    "acc_plot.set_label(\"Accuracy\")\n",
    "ax2.set_ylabel(\"Accuracy\")\n",
    "ax2.legend(loc = \"upper right\")\n",
    "plt.title(\"Loss vs Accuracy\")\n",
    "plt.savefig(datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\") + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ff3_jdV0XumE"
   },
   "outputs": [],
   "source": [
    "def predict(sample):\n",
    "  enc_input = np.expand_dims(sample, 0)\n",
    "\n",
    "  dec_input = en_tokenize.predict([\"sos\"])\n",
    "  prediction = []\n",
    "  for i in range(en_timesteps):\n",
    "    step_pred = model.predict([enc_input, dec_input])[0]\n",
    "    word_index = tf.argmax(step_pred[i])\n",
    "    dec_input[0][i + 1] = word_index\n",
    "    word = en_tokenize.get_layer(\"text_vectorization_1\").get_vocabulary()[word_index]\n",
    "    if word == \"eos\":\n",
    "      break\n",
    "    prediction.append(word)\n",
    "\n",
    "  return \" \".join(prediction)\n",
    "\n",
    "source = zh_train_ds[350]\n",
    "target = en_train_ds[350]\n",
    "\n",
    "print(\"Prediction:\\n\" + predict(source))\n",
    "label_sen = [en_tokenize.get_layer(\"text_vectorization_1\").get_vocabulary()[word] for word in target if word != 0]\n",
    "print(\"Target:\\n\" + \" \".join(label_sen[1:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnfKpwlc0C4A",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# **RHNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 512\n",
    "embed_units = 512\n",
    "epochs = 50\n",
    "batch_size = 1024\n",
    "target_acc = .9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "kD9_nCow0Hk3"
   },
   "outputs": [],
   "source": [
    "class HighwayEncoderCell(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, units):\n",
    "    super(HighwayEncoderCell, self).__init__()\n",
    "    self.units = units\n",
    "    self.state_size = units\n",
    "    self.output_size = units\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.w_T_x = self.add_weight(shape = (input_shape[-1], self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.w_T_s = self.add_weight(shape = (self.units, self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.b_T = self.add_weight(shape = (self.units,), initializer = \"random_normal\", trainable = True)\n",
    "\n",
    "    self.w_H_x = self.add_weight(shape = (input_shape[-1], self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.w_H_s = self.add_weight(shape = (self.units, self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.b_H = self.add_weight(shape = (self.units,), initializer = \"random_normal\", trainable = True)\n",
    "\n",
    "    self.w_C_x = self.add_weight(shape = (input_shape[-1], self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.w_C_s = self.add_weight(shape = (self.units, self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.b_C = self.add_weight(shape = (self.units,), initializer = \"random_normal\", trainable = True)\n",
    "\n",
    "    self.built = True\n",
    "\n",
    "  def call(self, inputs, states):\n",
    "    prev_s = states[0]\n",
    "\n",
    "    T = tf.matmul(inputs, self.w_T_x)\n",
    "    T += tf.matmul(prev_s, self.w_T_s)\n",
    "    T += self.b_T\n",
    "    T = tf.keras.activations.sigmoid(T)\n",
    "\n",
    "    H = tf.matmul(inputs, self.w_H_x)\n",
    "    H += tf.matmul(prev_s, self.w_H_s)\n",
    "    H += self.b_H\n",
    "    H = tf.keras.activations.tanh(H)\n",
    "\n",
    "    C = tf.matmul(inputs, self.w_C_x)\n",
    "    C += tf.matmul(prev_s, self.w_C_s)\n",
    "    C += self.b_C\n",
    "    C = tf.keras.activations.sigmoid(C)\n",
    "\n",
    "    s = tf.math.multiply(T, H) + tf.math.multiply(prev_s, C)\n",
    "    \n",
    "    return s, [s]\n",
    "\n",
    "class HighwayManyInputDecoderCell(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, units, vocab_size):\n",
    "    super(HighwayManyInputDecoderCell, self).__init__()\n",
    "    self.units = units\n",
    "    self.state_size = units\n",
    "    self.output_size = units\n",
    "    self.vocab_size = vocab_size\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.w_T_x = self.add_weight(shape = (input_shape[-1], self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.w_T_s = self.add_weight(shape = (self.units, self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.b_T = self.add_weight(shape = (self.units,), initializer = \"random_normal\", trainable = True)\n",
    "\n",
    "    self.w_H_x = self.add_weight(shape = (input_shape[-1], self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.w_H_s = self.add_weight(shape = (self.units, self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.b_H = self.add_weight(shape = (self.units,), initializer = \"random_normal\", trainable = True)\n",
    "\n",
    "    self.w_C_x = self.add_weight(shape = (input_shape[-1], self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.w_C_s = self.add_weight(shape = (self.units, self.units), initializer = \"random_normal\", trainable = True)\n",
    "    self.b_C = self.add_weight(shape = (self.units,), initializer = \"random_normal\", trainable = True)\n",
    "\n",
    "    self.w_softmax = self.add_weight(shape = (self.units, self.vocab_size), initializer = \"random_normal\", trainable = True)\n",
    "    self.b_softmax = self.add_weight(shape = (self.vocab_size,), initializer = \"random_normal\", trainable = True)\n",
    "\n",
    "    self.built = True\n",
    "\n",
    "  def call(self, inputs, states):\n",
    "    prev_s = states[0]\n",
    "\n",
    "    T = tf.matmul(inputs, self.w_T_x)\n",
    "    T += tf.matmul(prev_s, self.w_T_s)\n",
    "    T += self.b_T\n",
    "    T = tf.keras.activations.sigmoid(T)\n",
    "\n",
    "    H = tf.matmul(inputs, self.w_H_x)\n",
    "    H += tf.matmul(prev_s, self.w_H_s)\n",
    "    H += self.b_H\n",
    "    H = tf.keras.activations.tanh(H)\n",
    "\n",
    "    C = tf.matmul(inputs, self.w_C_x)\n",
    "    C += tf.matmul(prev_s, self.w_C_s)\n",
    "    C += self.b_C\n",
    "    C = tf.keras.activations.sigmoid(C)\n",
    "\n",
    "    s = tf.math.multiply(T, H) + tf.math.multiply(prev_s, C)\n",
    "\n",
    "    y = tf.matmul(s, self.w_softmax)\n",
    "    y += self.b_softmax\n",
    "    y = tf.keras.activations.softmax(y)\n",
    "    \n",
    "    return y, [s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQYLv09IoH9K"
   },
   "source": [
    "**Direct Sequence-to-Sequence Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GGYUdI1xOeB6",
    "outputId": "2f8b5856-fefa-412f-b20e-a5c905d89d1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_25 (InputLayer)       [(None, 200)]             0         \n",
      "                                                                 \n",
      " embedding_24 (Embedding)    (None, 200, 512)          15360000  \n",
      "                                                                 \n",
      " rnn_23 (RNN)                (None, 200, 512)          1574400   \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 200, 30000)       15390000  \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,324,400\n",
      "Trainable params: 32,324,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape = (zh_timesteps))\n",
    "x = tf.keras.layers.Embedding(zh_vocab_size, embed_units, input_length = zh_timesteps, mask_zero = True)(inputs)\n",
    "h = tf.keras.layers.RNN(HighwayEncoderCell(units), return_sequences = True)(x)\n",
    "y = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(en_vocab_size, activation = \"softmax\"))(h)\n",
    "model = tf.keras.Model(inputs = inputs, outputs = y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "roUUQVaFoWtS"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate = .01)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "model.compile(optimizer = optimizer, loss = loss, metrics = [\"accuracy\"])\n",
    "history = model.fit(zh_train_ds, en_train_ds, batch_size = batch_size, epochs = epochs, validation_data = (zh_val_ds, en_val_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfaPMWHRpD0M"
   },
   "source": [
    "**Encoder-Decoder Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "MO5ZZQ9kpH3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_27 (InputLayer)          [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " input_28 (InputLayer)          [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_26 (Embedding)       (None, 200, 512)     15360000    ['input_27[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_27 (Embedding)       (None, 200, 512)     15360000    ['input_28[0][0]']               \n",
      "                                                                                                  \n",
      " rnn_25 (RNN)                   [(None, 512),        1574400     ['embedding_26[0][0]']           \n",
      "                                 (None, 512)]                                                     \n",
      "                                                                                                  \n",
      " rnn_26 (RNN)                   (None, 200, 30000)   16964400    ['embedding_27[0][0]',           \n",
      "                                                                  'rnn_25[0][1]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 49,258,800\n",
      "Trainable params: 49,258,800\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs_encoder = tf.keras.Input(shape = (zh_timesteps))\n",
    "x = tf.keras.layers.Embedding(zh_vocab_size, embed_units, input_length = zh_timesteps, mask_zero = True)(inputs_encoder)\n",
    "h, h_s = tf.keras.layers.RNN(HighwayEncoderCell(units), return_state = True)(x)\n",
    "\n",
    "inputs_decoder = tf.keras.Input(shape = (en_timesteps))\n",
    "h = tf.keras.layers.Embedding(en_vocab_size, embed_units, input_length = en_timesteps, mask_zero = True)(inputs_decoder)\n",
    "y = tf.keras.layers.RNN(HighwayManyInputDecoderCell(units, en_vocab_size), return_sequences = True)(h, initial_state = [h_s])\n",
    "model = tf.keras.Model(inputs = [inputs_encoder, inputs_decoder], outputs = y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlgpJr69pK0f"
   },
   "outputs": [],
   "source": [
    "class MaskedLoss(tf.keras.losses.Loss):\n",
    "  def __init__(self):\n",
    "    self.name = \"masked_loss\"\n",
    "    self.reduction = tf.keras.losses.Reduction.NONE\n",
    "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(reduction = self.reduction)\n",
    "\n",
    "  def __call__(self, y_true, y_pred, sample_weight):\n",
    "    loss = self.loss(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(y_true != 0, tf.float32)\n",
    "    loss *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss)\n",
    "\n",
    "class accuracy_callback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs = {}):\n",
    "    if(logs.get(\"accuracy\") >= target_acc):\n",
    "      self.model.stop_training = True\n",
    "\n",
    "acc_call = accuracy_callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4v3EIdQNpMl8"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate = .01)\n",
    "loss = MaskedLoss()\n",
    "model.compile(optimizer = optimizer, loss = loss, metrics = [\"accuracy\"])\n",
    "history = model.fit([zh_train_ds, en_train_ds], en_dec_train_ds, batch_size = batch_size, epochs = epochs, callbacks = [acc_call])\n",
    "# history = model.fit([zh_train_ds, en_train_ds], en_train_ds, batch_size = 64, epochs = 50, validation_data = ([zh_val_ds, en_val_ds], en_dec_val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training on multiple GPUs\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "gpus = tf.config.list_logical_devices(\"GPU\")\n",
    "strategy = tf.distribute.MirroredStrategy(gpus)\n",
    "with strategy.scope():\n",
    "  inputs_encoder = tf.keras.Input(shape = (zh_timesteps))\n",
    "  x = tf.keras.layers.Embedding(zh_vocab_size, embed_units, input_length = zh_timesteps, mask_zero = True)(inputs_encoder)\n",
    "  h, h_s = tf.keras.layers.RNN(HighwayEncoderCell(units), return_state = True)(x)\n",
    "\n",
    "  inputs_decoder = tf.keras.Input(shape = (en_timesteps))\n",
    "  h = tf.keras.layers.Embedding(en_vocab_size, embed_units, input_length = en_timesteps, mask_zero = True)(inputs_decoder)\n",
    "  y = tf.keras.layers.RNN(HighwayManyInputDecoderCell(units, en_vocab_size), return_sequences = True)(h, initial_state = [h_s])\n",
    "  model = tf.keras.Model(inputs = [inputs_encoder, inputs_decoder], outputs = y)\n",
    "\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate = .01)\n",
    "  loss = MaskedLoss()\n",
    "  model.compile(optimizer = optimizer, loss = loss, metrics = [\"accuracy\"])\n",
    "  history = model.fit([zh_train_ds, en_train_ds], en_dec_train_ds, batch_size = batch_size, epochs = epochs, callbacks = [acc_call])\n",
    "  # history = model.fit([zh_train_ds, en_train_ds], en_train_ds, batch_size = 64, epochs = 50, validation_data = ([zh_val_ds, en_val_ds], en_dec_val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRQ-SZo5pQ6y"
   },
   "outputs": [],
   "source": [
    "loss = history.history[\"loss\"]\n",
    "accuracy = history.history[\"accuracy\"]\n",
    "# val_loss = history.history[\"val_loss\"]\n",
    "# val_accuracy = history.history[\"val_accuracy\"]\n",
    "timerange = range(len(loss))\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "loss_plot, = ax.plot(timerange, loss, color = \"blue\")\n",
    "loss_plot.set_label(\"Loss\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend(loc = \"upper left\")\n",
    "ax2 = ax.twinx()\n",
    "acc_plot, = ax2.plot(timerange, accuracy, color = \"purple\")\n",
    "acc_plot.set_label(\"Accuracy\")\n",
    "ax2.set_ylabel(\"Accuracy\")\n",
    "ax2.legend(loc = \"upper right\")\n",
    "plt.title(\"Loss vs Accuracy\")\n",
    "plt.savefig(datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\") + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pHehCz6VpTYe"
   },
   "outputs": [],
   "source": [
    "def predict(sample):\n",
    "  enc_input = np.expand_dims(sample, 0)\n",
    "\n",
    "  dec_input = en_tokenize.predict([\"sos\"])\n",
    "  prediction = []\n",
    "  for i in range(en_timesteps):\n",
    "    step_pred = model.predict([enc_input, dec_input])[0]\n",
    "    word_index = tf.argmax(step_pred[i])\n",
    "    dec_input[0][i + 1] = word_index\n",
    "    word = en_tokenize.get_layer(\"text_vectorization_1\").get_vocabulary()[word_index]\n",
    "    if word == \"eos\":\n",
    "      break\n",
    "    prediction.append(word)\n",
    "\n",
    "  return \" \".join(prediction)\n",
    "\n",
    "source = zh_train_ds[350]\n",
    "target = en_train_ds[350]\n",
    "\n",
    "print(\"Prediction:\\n\" + predict(source))\n",
    "label_sen = [en_tokenize.get_layer(\"text_vectorization_1\").get_vocabulary()[word] for word in target if word != 0]\n",
    "print(\"Target:\\n\" + \" \".join(label_sen[1:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zp0K8y430IgI",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# **Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "Xt6oy97kWYOY"
   },
   "outputs": [],
   "source": [
    "num_layers = 6\n",
    "d_model = 512\n",
    "dff = 2048\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1\n",
    "epochs = 50\n",
    "batch_size = 1024\n",
    "target_acc = .9\n",
    "graph = True\n",
    "save_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "dsru6kGM0J0Z"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(t, d_model):\n",
    "  pos_encoding = np.array(np.arange(d_model))\n",
    "  pos_encoding = 1 / np.power(10000, ((2 * (pos_encoding // 2)) / d_model))\n",
    "  pos_encoding = [pos_encoding] * np.expand_dims(np.arange(t), 1)\n",
    "  \n",
    "  pos_encoding[:, 0::2] = np.sin(pos_encoding[:, 0::2])\n",
    "  pos_encoding[:, 1::2] = np.cos(pos_encoding[:, 1::2])\n",
    "\n",
    "  pos_encoding = np.expand_dims(pos_encoding, 0)\n",
    "\n",
    "  return tf.cast(pos_encoding, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "peUXmh-5Iar_"
   },
   "outputs": [],
   "source": [
    "def padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def future_mask(length):\n",
    "  return 1 - tf.linalg.band_part(tf.ones((length, length)), -1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "4sjTy2rXJILH"
   },
   "outputs": [],
   "source": [
    "def sdp_attention(q, k, v, mask):\n",
    "  qk = tf.matmul(q, k, transpose_b = True)\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  qk /= tf.math.sqrt(dk)\n",
    "\n",
    "  if mask is not None:\n",
    "    qk += (mask * -1e9)\n",
    "\n",
    "  softmax = tf.nn.softmax(qk, axis = -1)\n",
    "\n",
    "  return tf.matmul(softmax, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "ITdSiSfkKi9l"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  \n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.d_model = d_model\n",
    "    self.num_heads = num_heads\n",
    "\n",
    "    self.dims = self.d_model // self.num_heads\n",
    "\n",
    "    self.Wq = tf.keras.layers.Dense(d_model)\n",
    "    self.Wk = tf.keras.layers.Dense(d_model)\n",
    "    self.Wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "  def split_heads(self, x, batch_size):\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.d_model // self.num_heads))\n",
    "    return tf.transpose(x, perm = [0, 2, 1, 3])\n",
    "\n",
    "  def call(self, qx, kx, vx, mask):\n",
    "    batch_size = tf.shape(qx)[0]\n",
    "\n",
    "    q = self.Wq(qx)\n",
    "    k = self.Wk(kx)\n",
    "    v = self.Wv(vx)\n",
    "\n",
    "    q = self.split_heads(q, batch_size)\n",
    "    k = self.split_heads(k, batch_size)\n",
    "    v = self.split_heads(v, batch_size)\n",
    "\n",
    "    sdp = sdp_attention(q, k, v, mask)\n",
    "\n",
    "    sdp = tf.transpose(sdp, perm = [0, 2, 1, 3])\n",
    "\n",
    "    sdp_concat = tf.reshape(sdp, (batch_size, -1, self.d_model))\n",
    "\n",
    "    return self.linear(sdp_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "QrxO36HWL5_1"
   },
   "outputs": [],
   "source": [
    "class EncoderUnit(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, dff, rate = .1):\n",
    "    super(EncoderUnit, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model = d_model, num_heads = num_heads)\n",
    "    \n",
    "    self.ff1 = tf.keras.layers.Dense(dff, activation = \"relu\")\n",
    "    self.ff2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    self.norm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "    self.norm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "\n",
    "    self.drop1 = tf.keras.layers.Dropout(rate)\n",
    "    self.drop2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, training, mask):\n",
    "    mha_out = self.mha(x, x, x, mask)\n",
    "    norm1 = self.drop1(mha_out, training = training)\n",
    "    add1 = self.norm1(x + norm1)\n",
    "\n",
    "    ff_out = self.ff1(add1)\n",
    "    ff_out = self.ff2(ff_out)\n",
    "    norm2 = self.drop2(ff_out, training = training)\n",
    "    add2 = self.norm2(add1 + norm2)\n",
    "\n",
    "    return add2\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, num_layers, t, d_model, num_heads, dff, vocab_size, rate = .1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.num_layers = num_layers\n",
    "    self.d_model = d_model\n",
    "    self.t = t\n",
    "\n",
    "    self.embed = tf.keras.layers.Embedding(vocab_size, d_model)\n",
    "    self.pos_enc = positional_encoding(self.t, self.d_model)\n",
    "\n",
    "    self.enc_units = [EncoderUnit(d_model = d_model,\n",
    "                                  num_heads = num_heads,\n",
    "                                  dff = dff,\n",
    "                                  rate = rate) for _ in range(num_layers)]\n",
    "\n",
    "    self.drop = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, training, mask):\n",
    "    x = self.embed(x)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_enc[:, :tf.shape(x)[1], :]\n",
    "\n",
    "    x = self.drop(x, training = training)\n",
    "\n",
    "    for enc in self.enc_units:\n",
    "      x = enc(x, training, mask)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "WTettl55NxJ3"
   },
   "outputs": [],
   "source": [
    "class DecoderUnit(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, dff, rate = .1):\n",
    "    super(DecoderUnit, self).__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model = d_model, num_heads = num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model = d_model, num_heads = num_heads)\n",
    "\n",
    "    self.ff1 = tf.keras.layers.Dense(dff, activation = \"relu\")\n",
    "    self.ff2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    self.norm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "    self.norm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "    self.norm3 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "\n",
    "    self.drop1 = tf.keras.layers.Dropout(rate)\n",
    "    self.drop2 = tf.keras.layers.Dropout(rate)\n",
    "    self.drop3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, enc_out, training, fut_mask, pad_mask):\n",
    "    mha1_out = self.mha1(x, x, x, fut_mask)\n",
    "    norm1 = self.drop1(mha1_out, training = training)\n",
    "    add1 = self.norm1(x + norm1)\n",
    "\n",
    "    mha2_out = self.mha2(add1, enc_out, enc_out, pad_mask)\n",
    "    norm2 = self.drop2(mha2_out, training = training)\n",
    "    add2 = self.norm2(add1 + norm2)\n",
    "\n",
    "    ff_out = self.ff1(add2)\n",
    "    ff_out = self.ff2(ff_out)\n",
    "    norm3 = self.drop3(ff_out, training = training)\n",
    "    add3 = self.norm3(add2 + norm3)\n",
    "\n",
    "    return add3\n",
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, num_layers, t, d_model, num_heads, dff, vocab_size, rate = .1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.num_layers = num_layers\n",
    "    self.d_model = d_model\n",
    "    self.t = t\n",
    "\n",
    "    self.embed = tf.keras.layers.Embedding(vocab_size, d_model)\n",
    "    self.pos_enc = positional_encoding(self.t, self.d_model)\n",
    "\n",
    "    self.dec_units = [DecoderUnit(d_model = d_model,\n",
    "                                  num_heads = num_heads,\n",
    "                                  dff = dff,\n",
    "                                  rate = rate) for _ in range(num_layers)]\n",
    "\n",
    "    self.drop = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, enc_out, training, fut_mask, pad_mask):\n",
    "    x = self.embed(x)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_enc[:, :tf.shape(x)[1], :]\n",
    "\n",
    "    x = self.drop(x, training = training)\n",
    "\n",
    "    for dec in self.dec_units:\n",
    "      x = dec(x, enc_out, training, fut_mask, pad_mask)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "f3IXemu4POuR"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, num_layers, t, d_model, num_heads, dff, input_vocab_size, output_vocab_size, rate = .1):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.enc = Encoder(num_layers = num_layers,\n",
    "                       t = t,\n",
    "                       d_model = d_model,\n",
    "                       num_heads = num_heads,\n",
    "                       dff = dff,\n",
    "                       vocab_size = input_vocab_size,\n",
    "                       rate = rate)\n",
    "    self.dec = Decoder(num_layers = num_layers,\n",
    "                       t = t,\n",
    "                       d_model = d_model,\n",
    "                       num_heads = num_heads,\n",
    "                       dff = dff,\n",
    "                       vocab_size = output_vocab_size,\n",
    "                       rate = rate)\n",
    "    \n",
    "    self.linear = tf.keras.layers.Dense(output_vocab_size)\n",
    "\n",
    "  def call(self, inputs, training):\n",
    "    x, y = inputs\n",
    "\n",
    "    pad_mask = padding_mask(x)\n",
    "    fut_mask = future_mask(tf.shape(y)[1])\n",
    "    dec_pad_mask = padding_mask(y)\n",
    "    fut_mask = tf.maximum(dec_pad_mask, fut_mask)\n",
    "\n",
    "    enc_out = self.enc(x, training, pad_mask)\n",
    "\n",
    "    dec_out = self.dec(y, enc_out, training, fut_mask, pad_mask)\n",
    "\n",
    "    t_out = self.linear(dec_out)\n",
    "\n",
    "    return(t_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "kHh2_9UIaaIW"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \n",
    "  def __init__(self, d_model, warmup_steps = 4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "  \n",
    "  def get_config(self):\n",
    "    config = {\"d_model\": self.d_model,\n",
    "              \"warmup_steps\": self.warmup_steps}\n",
    "    \n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZHkxwIVaehA"
   },
   "outputs": [],
   "source": [
    "# custom training loop\n",
    "lr = CustomSchedule(d_model)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = \"none\")\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype = loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.keras.backend.mean(tf.reduce_sum(loss_) / tf.reduce_sum(mask))\n",
    "  # return tf.nn.compute_average_loss([loss_], global_batch_size = batch_size)\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "  accuracies = tf.equal(real, tf.argmax(pred, axis = 2))\n",
    "\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "  accuracies = tf.cast(accuracies, dtype = tf.float32)\n",
    "  mask = tf.cast(mask, dtype = tf.float32)\n",
    "  return tf.reduce_sum(accuracies) / tf.reduce_sum(mask)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name = \"train_loss\")\n",
    "train_accuracy = tf.keras.metrics.Mean(name = \"train_accuracy\")\n",
    "validation_loss = tf.keras.metrics.Mean(name = \"validation_loss\")\n",
    "validation_accuracy = tf.keras.metrics.Mean(name = \"validation_accuracy\")\n",
    "\n",
    "gpus = tf.config.list_logical_devices(\"GPU\")\n",
    "strategy = tf.distribute.MirroredStrategy(gpus)\n",
    "with strategy.scope():\n",
    "  model = Transformer(\n",
    "    num_layers = num_layers,\n",
    "    t = zh_max_len,\n",
    "    d_model = d_model,\n",
    "    num_heads = num_heads,\n",
    "    dff = dff,\n",
    "    input_vocab_size = zh_vocab_size,\n",
    "    output_vocab_size = en_vocab_size,\n",
    "    rate = dropout_rate)\n",
    "  \n",
    "  optimizer = tf.keras.optimizers.Adam(lr, beta_1 = 0.9, beta_2 = 0.98, epsilon = 1e-9)\n",
    "  \n",
    "en_train_ds_pad = np.concatenate((en_train_ds, np.zeros((en_train_ds.shape[0], 1))), axis = 1)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((zh_train_ds.astype(np.int64), en_train_ds_pad.astype(np.int64)))\n",
    "train_batches = train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "train_batches = strategy.experimental_distribute_dataset(train_batches)\n",
    "\n",
    "en_val_ds_pad = np.concatenate((en_val_ds, np.zeros((en_val_ds.shape[0], 1))), axis = 1)\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((zh_val_ds.astype(np.int64), en_val_ds_pad.astype(np.int64)))\n",
    "validation_batches = validation_dataset.batch(batch_size // 8).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_step_signature = [tf.TensorSpec(shape = (None, None), dtype = tf.int64), tf.TensorSpec(shape = (None, None), dtype = tf.int64)]\n",
    "\n",
    "def train_step(x, y):\n",
    "  y_in = y[:, :-1]\n",
    "  y_out = y[:, 1:]\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = model([x, y_in], training = True)\n",
    "    loss = loss_function(y_out, predictions)\n",
    "    \n",
    "  train_accuracy(accuracy_function(y_out, predictions))\n",
    "\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "  \n",
    "  return loss\n",
    "  \n",
    "@tf.function\n",
    "def distributed_train_step(dist_x, dist_y):\n",
    "  single_loss = strategy.run(train_step, args = (dist_x, dist_y,))\n",
    "  return strategy.reduce(tf.distribute.ReduceOp.SUM, single_loss, axis = None)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  validation_loss.reset_states()\n",
    "  validation_accuracy.reset_states()\n",
    "\n",
    "  iterate = tqdm(enumerate(train_batches), total = -(zh_train_ds.shape[0] // -batch_size))\n",
    "  for (batch, (x, y)) in iterate:\n",
    "    batch_loss = distributed_train_step(x, y)\n",
    "    train_loss(batch_loss)\n",
    "    iterate.set_description(f\"loss: {train_loss.result():.2f} - accuracy: {train_accuracy.result():.4f}\")\n",
    "    \n",
    "  for (batch, (x, y)) in enumerate(validation_batches):\n",
    "    predictions = model([x, y[:, :-1]], training = False)\n",
    "    validation_loss(loss_function(y[:, 1:], predictions))\n",
    "    validation_accuracy(accuracy_function(y[:, 1:], predictions))\n",
    "    \n",
    "  print(f\"validation loss: {validation_loss.result():.4f} - validation accuracy: {validation_accuracy.result():.4f}\")\n",
    "  \n",
    "  if train_accuracy.result() >= target_acc:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training with keras.model.fit\n",
    "class accuracy_callback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs = {}):\n",
    "    if(logs.get(\"accuracy_function\") >= target_acc):\n",
    "      self.model.stop_training = True\n",
    "\n",
    "acc_call = accuracy_callback()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = \"none\")\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype = loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.keras.backend.mean(tf.reduce_sum(loss_) / tf.reduce_sum(mask))\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "  accuracies = tf.equal(real, tf.cast(tf.argmax(pred, axis = 2), tf.float32))\n",
    "\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "  accuracies = tf.cast(accuracies, dtype = tf.float32)\n",
    "  mask = tf.cast(mask, dtype = tf.float32)\n",
    "  return tf.keras.backend.mean(tf.reduce_sum(accuracies) / tf.reduce_sum(mask))\n",
    "\n",
    "en_train_ds_pad = np.concatenate((en_train_ds, np.zeros((en_train_ds.shape[0], 1))), axis = 1)\n",
    "en_dec_train_ds = en_train_ds_pad[:, 1:]\n",
    "en_train_ds = en_train_ds_pad[:, :-1]\n",
    "\n",
    "en_val_ds_pad = np.concatenate((en_val_ds, np.zeros((en_val_ds.shape[0], 1))), axis = 1)\n",
    "en_dec_val_ds = en_val_ds_pad[:, 1:]\n",
    "en_val_ds = en_val_ds_pad[:, :-1]\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "gpus = tf.config.list_logical_devices(\"GPU\")\n",
    "strategy = tf.distribute.MirroredStrategy(gpus)\n",
    "with strategy.scope():\n",
    "  model = Transformer(\n",
    "    num_layers = num_layers,\n",
    "    t = zh_max_len,\n",
    "    d_model = d_model,\n",
    "    num_heads = num_heads,\n",
    "    dff = dff,\n",
    "    input_vocab_size = zh_vocab_size,\n",
    "    output_vocab_size = en_vocab_size,\n",
    "    rate = dropout_rate)\n",
    "\n",
    "  lr = CustomSchedule(d_model)\n",
    "  optimizer = tf.keras.optimizers.Adam(lr, beta_1 = 0.9, beta_2 = 0.98, epsilon = 1e-9)\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = loss_function, metrics = [accuracy_function])\n",
    "# history = model.fit([zh_train_ds, en_train_ds], en_dec_train_ds, batch_size = batch_size, epochs = epochs, callbacks = [acc_call])\n",
    "history = model.fit([zh_train_ds, en_train_ds], en_dec_train_ds, batch_size = batch_size, epochs = epochs, callbacks = [acc_call], validation_data = ([zh_val_ds, en_val_ds], en_dec_val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_8 (Encoder)         multiple                  34274304  \n",
      "                                                                 \n",
      " decoder_6 (Decoder)         multiple                  40584192  \n",
      "                                                                 \n",
      " dense_383 (Dense)           multiple                  15390000  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 90,248,496\n",
      "Trainable params: 90,248,496\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if graph:\n",
    "  loss = history.history[\"loss\"]\n",
    "  accuracy = history.history[\"accuracy_function\"]\n",
    "  val_loss = history.history[\"val_loss\"]\n",
    "  val_accuracy = history.history[\"val_accuracy_function\"]\n",
    "  timerange = range(len(loss))\n",
    "\n",
    "  fig,ax = plt.subplots()\n",
    "  train_loss_plot, = ax.plot(timerange, loss, color = \"blue\")\n",
    "  val_loss_plot, = ax.plot(timerange, val_loss, color = \"cyan\")\n",
    "  train_loss_plot.set_label(\"Train Loss\")\n",
    "  val_loss_plot.set_label(\"Validation Loss\")\n",
    "  ax.set_xlabel(\"Epoch\")\n",
    "  ax.set_ylabel(\"Loss\")\n",
    "  ax.legend(loc = \"upper left\")\n",
    "  ax2 = ax.twinx()\n",
    "  train_acc_plot, = ax2.plot(timerange, accuracy, color = \"purple\")\n",
    "  val_acc_plot, = ax2.plot(timerange, val_accuracy, color = \"pink\")\n",
    "  train_acc_plot.set_label(\"Train Accuracy\")\n",
    "  val_acc_plot.set_label(\"Validation Accuracy\")\n",
    "  ax2.set_ylabel(\"Accuracy\")\n",
    "  ax2.legend(loc = \"upper right\")\n",
    "  plt.title(\"Loss vs Accuracy\")\n",
    "  plt.savefig(f\"samples{train_samples}_dims{d_model}_date{datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model:\n",
    "  model.save(f\"model_{datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zp0K8y430IgI"
   },
   "source": [
    "# **Convolutional Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Xt6oy97kWYOY"
   },
   "outputs": [],
   "source": [
    "num_layers = 6\n",
    "d_model = 512\n",
    "dff = 2048\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1\n",
    "kernels = [\"1d1\", \"3d1\", \"5d1\", \"7d1\", \"3d2\", \"5d2\", \"7d2\"]\n",
    "epochs = 50\n",
    "batch_size = 1024\n",
    "target_acc = .9\n",
    "graph = True\n",
    "save_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dsru6kGM0J0Z"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(t, d_model):\n",
    "  pos_encoding = np.array(np.arange(d_model))\n",
    "  pos_encoding = 1 / np.power(10000, ((2 * (pos_encoding // 2)) / d_model))\n",
    "  pos_encoding = [pos_encoding] * np.expand_dims(np.arange(t), 1)\n",
    "  \n",
    "  pos_encoding[:, 0::2] = np.sin(pos_encoding[:, 0::2])\n",
    "  pos_encoding[:, 1::2] = np.cos(pos_encoding[:, 1::2])\n",
    "\n",
    "  pos_encoding = np.expand_dims(pos_encoding, 0)\n",
    "\n",
    "  return tf.cast(pos_encoding, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "peUXmh-5Iar_"
   },
   "outputs": [],
   "source": [
    "def padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def future_mask(length):\n",
    "  return 1 - tf.linalg.band_part(tf.ones((length, length)), -1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4sjTy2rXJILH"
   },
   "outputs": [],
   "source": [
    "def sdp_attention(q, k, v, mask):\n",
    "  qk = tf.matmul(q, k, transpose_b = True)\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  qk /= tf.math.sqrt(dk)\n",
    "\n",
    "  if mask is not None:\n",
    "    qk += (mask * -1e9)\n",
    "\n",
    "  softmax = tf.nn.softmax(qk, axis = -1)\n",
    "\n",
    "  return tf.matmul(softmax, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ITdSiSfkKi9l"
   },
   "outputs": [],
   "source": [
    "class MaskedConv2D(tf.keras.layers.Layer):\n",
    "  \n",
    "  def __init__(self, filters, kernel_size, dilation_rate):\n",
    "    super(MaskedConv2D, self).__init__()\n",
    "    self.filters = filters\n",
    "    self.kernel_size = kernel_size\n",
    "    self.dilation_rate = dilation_rate\n",
    "    self.mask_width = self.kernel_size[0] // 2\n",
    "    self.mask = tf.constant(tf.concat([tf.ones((self.mask_width + 1, self.kernel_size[1])),\n",
    "                                       tf.zeros((self.mask_width, self.kernel_size[1]))], axis = 0))\n",
    "    self.conv2d = tf.keras.layers.Conv2D(filters = filters,\n",
    "                                         kernel_size = kernel_size,\n",
    "                                         dilation_rate = dilation_rate)\n",
    "    \n",
    "  def build(self, input_shape):\n",
    "    self.conv2d.build(input_shape)\n",
    "    self.convolution_op = self.conv2d.convolution_op\n",
    "\n",
    "  def masked_convolution_op(self, inputs, kernel, mask):\n",
    "    return self.convolution_op(inputs, tf.math.multiply(kernel, tf.reshape(mask, self.mask.shape + [1, 1])))\n",
    "\n",
    "  def call(self, x):\n",
    "    self.conv2d.convolution_op = functools.partial(self.masked_convolution_op, mask = self.mask)\n",
    "    return self.conv2d.call(x)\n",
    "\n",
    "class EncoderMultiHeadAttention(tf.keras.layers.Layer):\n",
    "  \n",
    "  def __init__(self, d_model, num_heads, kernels):\n",
    "    super(EncoderMultiHeadAttention, self).__init__()\n",
    "    self.d_model = d_model\n",
    "    self.num_heads = num_heads\n",
    "    self.kernels = [kernel for kernel in kernels if bool(re.match(\"\\d+d\\d+\", kernel))]\n",
    "    \n",
    "    self.filter_sizes = [int(kernel.split(\"d\")[0]) for kernel in self.kernels]\n",
    "    self.dilations = [int(kernel.split(\"d\")[1]) for kernel in self.kernels]\n",
    "    \n",
    "    self.num_filters = [-(self.d_model // -len(self.filter_sizes))] * len(self.filter_sizes)\n",
    "    self.num_filters[-1] = self.d_model - ((len(self.num_filters) - 1) * self.num_filters[0])\n",
    "    \n",
    "    for i in range(len(self.kernels)):\n",
    "      if self.dilations[i] < 1:\n",
    "        raise ValueError(\"dilation size must be 1 or more\")\n",
    "      if self.filter_sizes[i] % 2 != 1:\n",
    "        raise ValueError(\"filter width must be an odd number\")\n",
    "      if self.filter_sizes[i] == 1 and self.dilations[i] != 1:\n",
    "        raise ValueError(\"dilation is not valid if kernel width is 1\")\n",
    "    \n",
    "    assert self.d_model % self.num_heads == 0\n",
    "\n",
    "    self.dims = self.d_model // self.num_heads\n",
    "\n",
    "    self.Wq = [tf.keras.layers.Conv2D(filters = self.num_filters[i],\n",
    "                                      kernel_size = (self.filter_sizes[i], self.d_model),\n",
    "                                      dilation_rate = (self.dilations[i], 1)) for i in range(len(self.kernels))]\n",
    "    self.Wk = [tf.keras.layers.Conv2D(filters = self.num_filters[i],\n",
    "                                      kernel_size = (self.filter_sizes[i], self.d_model),\n",
    "                                      dilation_rate = (self.dilations[i], 1)) for i in range(len(self.kernels))]\n",
    "    self.Wv = [tf.keras.layers.Conv2D(filters = self.num_filters[i],\n",
    "                                      kernel_size = (self.filter_sizes[i], self.d_model),\n",
    "                                      dilation_rate = (self.dilations[i], 1)) for i in range(len(self.kernels))]\n",
    "\n",
    "    self.linear = tf.keras.layers.Dense(self.d_model)\n",
    "\n",
    "  def split_heads(self, x, batch_size):\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.d_model // self.num_heads))\n",
    "    return tf.transpose(x, perm = [0, 2, 1, 3])\n",
    "\n",
    "  def call(self, qx, kx, vx, mask):\n",
    "    batch_size = tf.shape(qx)[0]\n",
    "    \n",
    "    qs, ks, vs = [], [], []\n",
    "\n",
    "    for i in range(len(self.filter_sizes)):\n",
    "      pad_size = ((self.filter_sizes[i] - 1) * self.dilations[i]) // 2\n",
    "      if pad_size > 0:\n",
    "        qx_pad = tf.concat([tf.zeros((batch_size, pad_size, tf.shape(qx)[2])),\n",
    "                            qx,\n",
    "                            tf.zeros((batch_size, pad_size, tf.shape(qx)[2]))], axis = 1)\n",
    "        kx_pad = tf.concat([tf.zeros((batch_size, pad_size, tf.shape(kx)[2])),\n",
    "                            kx,\n",
    "                            tf.zeros((batch_size, pad_size, tf.shape(kx)[2]))], axis = 1)\n",
    "        vx_pad = tf.concat([tf.zeros((batch_size, pad_size, tf.shape(vx)[2])),\n",
    "                            vx,\n",
    "                            tf.zeros((batch_size, pad_size, tf.shape(vx)[2]))], axis = 1)\n",
    "      else:\n",
    "        qx_pad, kx_pad, vx_pad = qx, kx, vx\n",
    "      qx_pad = tf.expand_dims(qx_pad, axis = -1)\n",
    "      kx_pad = tf.expand_dims(kx_pad, axis = -1)\n",
    "      vx_pad = tf.expand_dims(vx_pad, axis = -1)\n",
    "      qi = self.Wq[i](qx_pad)\n",
    "      ki = self.Wk[i](kx_pad)\n",
    "      vi = self.Wv[i](vx_pad)\n",
    "      qi = tf.squeeze(qi)\n",
    "      ki = tf.squeeze(ki)\n",
    "      vi = tf.squeeze(vi)\n",
    "      qs.append(qi)\n",
    "      ks.append(ki)\n",
    "      vs.append(vi)\n",
    "      \n",
    "    q = tf.concat(qs, axis = 2)\n",
    "    k = tf.concat(ks, axis = 2)\n",
    "    v = tf.concat(vs, axis = 2)\n",
    "    \n",
    "    q = self.split_heads(q, batch_size)\n",
    "    k = self.split_heads(k, batch_size)\n",
    "    v = self.split_heads(v, batch_size)\n",
    "\n",
    "    sdp = sdp_attention(q, k, v, mask)\n",
    "\n",
    "    sdp = tf.transpose(sdp, perm = [0, 2, 1, 3])\n",
    "\n",
    "    sdp_concat = tf.reshape(sdp, (batch_size, -1, self.d_model))\n",
    "\n",
    "    return self.linear(sdp_concat)\n",
    "  \n",
    "class DecoderMultiHeadAttention(tf.keras.layers.Layer):\n",
    "  \n",
    "  def __init__(self, d_model, num_heads, kernels):\n",
    "    super(DecoderMultiHeadAttention, self).__init__()\n",
    "    self.d_model = d_model\n",
    "    self.num_heads = num_heads\n",
    "    self.kernels = [kernel for kernel in kernels if bool(re.match(\"\\d+d\\d+\", kernel))]\n",
    "    \n",
    "    self.filter_sizes = [int(kernel.split(\"d\")[0]) for kernel in self.kernels]\n",
    "    self.dilations = [int(kernel.split(\"d\")[1]) for kernel in self.kernels]\n",
    "    \n",
    "    self.num_filters = [-(self.d_model // -len(self.filter_sizes))] * len(self.filter_sizes)\n",
    "    self.num_filters[-1] = self.d_model - ((len(self.num_filters) - 1) * self.num_filters[0])\n",
    "    \n",
    "    for i in range(len(self.kernels)):\n",
    "      if self.dilations[i] < 1:\n",
    "        raise ValueError(\"dilation size must be 1 or more\")\n",
    "      if self.filter_sizes[i] % 2 != 1:\n",
    "        raise ValueError(\"filter width must be an odd number\")\n",
    "      if self.filter_sizes[i] == 1 and self.dilations[i] != 1:\n",
    "        raise ValueError(\"dilation is not valid if kernel width is 1\")\n",
    "    \n",
    "    assert self.d_model % self.num_heads == 0\n",
    "\n",
    "    self.dims = self.d_model // self.num_heads\n",
    "\n",
    "    self.Wq = [MaskedConv2D(filters = self.num_filters[i],\n",
    "                            kernel_size = (self.filter_sizes[i], self.d_model),\n",
    "                            dilation_rate = (self.dilations[i], 1)) for i in range(len(self.kernels))]\n",
    "    self.Wk = [MaskedConv2D(filters = self.num_filters[i],\n",
    "                            kernel_size = (self.filter_sizes[i], self.d_model),\n",
    "                            dilation_rate = (self.dilations[i], 1)) for i in range(len(self.kernels))]\n",
    "    self.Wv = [MaskedConv2D(filters = self.num_filters[i],\n",
    "                            kernel_size = (self.filter_sizes[i], self.d_model),\n",
    "                            dilation_rate = (self.dilations[i], 1)) for i in range(len(self.kernels))]\n",
    "\n",
    "    self.linear = tf.keras.layers.Dense(self.d_model)\n",
    "\n",
    "  def split_heads(self, x, batch_size):\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.d_model // self.num_heads))\n",
    "    return tf.transpose(x, perm = [0, 2, 1, 3])\n",
    "\n",
    "  def call(self, qx, kx, vx, mask):\n",
    "    batch_size = tf.shape(qx)[0]\n",
    "\n",
    "    qs, ks, vs = [], [], []\n",
    "\n",
    "    for i in range(len(self.filter_sizes)):\n",
    "      pad_size = ((self.filter_sizes[i] - 1) * self.dilations[i]) // 2\n",
    "      if pad_size > 0:\n",
    "        qx_pad = tf.concat([tf.zeros((batch_size, pad_size, tf.shape(qx)[2])),\n",
    "                            qx,\n",
    "                            tf.zeros((batch_size, pad_size, tf.shape(qx)[2]))], axis = 1)\n",
    "        kx_pad = tf.concat([tf.zeros((batch_size, pad_size, tf.shape(kx)[2])),\n",
    "                            kx,\n",
    "                            tf.zeros((batch_size, pad_size, tf.shape(kx)[2]))], axis = 1)\n",
    "        vx_pad = tf.concat([tf.zeros((batch_size, pad_size, tf.shape(vx)[2])),\n",
    "                            vx,\n",
    "                            tf.zeros((batch_size, pad_size, tf.shape(vx)[2]))], axis = 1)\n",
    "      else:\n",
    "        qx_pad, kx_pad, vx_pad = qx, kx, vx\n",
    "      qx_pad = tf.expand_dims(qx_pad, axis = -1)\n",
    "      kx_pad = tf.expand_dims(kx_pad, axis = -1)\n",
    "      vx_pad = tf.expand_dims(vx_pad, axis = -1)\n",
    "      qi = self.Wq[i](qx_pad)\n",
    "      ki = self.Wk[i](kx_pad)\n",
    "      vi = self.Wv[i](vx_pad)\n",
    "      qi = tf.squeeze(qi)\n",
    "      ki = tf.squeeze(ki)\n",
    "      vi = tf.squeeze(vi)\n",
    "      qs.append(qi)\n",
    "      ks.append(ki)\n",
    "      vs.append(vi)\n",
    "      \n",
    "    q = tf.concat(qs, axis = 2)\n",
    "    k = tf.concat(ks, axis = 2)\n",
    "    v = tf.concat(vs, axis = 2)\n",
    "    \n",
    "    q = self.split_heads(q, batch_size)\n",
    "    k = self.split_heads(k, batch_size)\n",
    "    v = self.split_heads(v, batch_size)\n",
    "\n",
    "    sdp = sdp_attention(q, k, v, mask)\n",
    "\n",
    "    sdp = tf.transpose(sdp, perm = [0, 2, 1, 3])\n",
    "\n",
    "    sdp_concat = tf.reshape(sdp, (batch_size, -1, self.d_model))\n",
    "\n",
    "    return self.linear(sdp_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "QrxO36HWL5_1"
   },
   "outputs": [],
   "source": [
    "class EncoderUnit(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, dff, rate = .1, kernels = [\"1d1\", \"3d1\", \"5d1\", \"7d1\"]):\n",
    "    super(EncoderUnit, self).__init__()\n",
    "\n",
    "    self.mha = EncoderMultiHeadAttention(d_model = d_model,\n",
    "                                         num_heads = num_heads,\n",
    "                                         kernels = kernels)\n",
    "    \n",
    "    self.ff1 = tf.keras.layers.Dense(dff, activation = \"relu\")\n",
    "    self.ff2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    self.norm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "    self.norm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "\n",
    "    self.drop1 = tf.keras.layers.Dropout(rate)\n",
    "    self.drop2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, training, mask):\n",
    "    mha_out = self.mha(x, x, x, mask)\n",
    "    norm1 = self.drop1(mha_out, training = training)\n",
    "    add1 = self.norm1(x + norm1)\n",
    "\n",
    "    ff_out = self.ff1(add1)\n",
    "    ff_out = self.ff2(ff_out)\n",
    "    norm2 = self.drop2(ff_out, training = training)\n",
    "    add2 = self.norm2(add1 + norm2)\n",
    "\n",
    "    return add2\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, num_layers, t, d_model, num_heads, dff, vocab_size, rate = .1, kernels = [\"1d1\", \"3d1\", \"5d1\", \"7d1\"]):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.num_layers = num_layers\n",
    "    self.d_model = d_model\n",
    "    self.t = t\n",
    "\n",
    "    self.embed = tf.keras.layers.Embedding(vocab_size, d_model)\n",
    "    self.pos_enc = positional_encoding(self.t, self.d_model)\n",
    "\n",
    "    self.enc_units = [EncoderUnit(d_model = d_model,\n",
    "                                  num_heads = num_heads,\n",
    "                                  dff = dff,\n",
    "                                  rate = rate,\n",
    "                                  kernels = kernels) for _ in range(num_layers)]\n",
    "\n",
    "    self.drop = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, training, mask):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    x = self.embed(x)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_enc[:, :seq_len, :]\n",
    "\n",
    "    x = self.drop(x, training = training)\n",
    "\n",
    "    for enc in self.enc_units:\n",
    "      x = enc(x, training, mask)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WTettl55NxJ3"
   },
   "outputs": [],
   "source": [
    "class DecoderUnit(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, dff, rate = .1, kernels = [\"1d1\", \"3d1\", \"5d1\", \"7d1\"]):\n",
    "    super(DecoderUnit, self).__init__()\n",
    "\n",
    "    self.mha1 = DecoderMultiHeadAttention(d_model = d_model,\n",
    "                                          num_heads = num_heads,\n",
    "                                          kernels = kernels)\n",
    "    self.mha2 = DecoderMultiHeadAttention(d_model = d_model,\n",
    "                                          num_heads = num_heads,\n",
    "                                          kernels = kernels)\n",
    "\n",
    "    self.ff1 = tf.keras.layers.Dense(dff, activation = \"relu\")\n",
    "    self.ff2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    self.norm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "    self.norm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "    self.norm3 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "\n",
    "    self.drop1 = tf.keras.layers.Dropout(rate)\n",
    "    self.drop2 = tf.keras.layers.Dropout(rate)\n",
    "    self.drop3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, enc_out, training, fut_mask, pad_mask):\n",
    "    mha1_out = self.mha1(x, x, x, fut_mask)\n",
    "    norm1 = self.drop1(mha1_out, training = training)\n",
    "    add1 = self.norm1(x + norm1)\n",
    "\n",
    "    mha2_out = self.mha2(add1, enc_out, enc_out, pad_mask)\n",
    "    norm2 = self.drop2(mha2_out, training = training)\n",
    "    add2 = self.norm2(add1 + norm2)\n",
    "\n",
    "    ff_out = self.ff1(add2)\n",
    "    ff_out = self.ff2(ff_out)\n",
    "    norm3 = self.drop3(ff_out, training = training)\n",
    "    add3 = self.norm3(add2 + norm3)\n",
    "\n",
    "    return add3\n",
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, num_layers, t, d_model, num_heads, dff, vocab_size, rate = .1, kernels = [\"1d1\", \"3d1\", \"5d1\", \"7d1\"]):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.num_layers = num_layers\n",
    "    self.d_model = d_model\n",
    "    self.t = t\n",
    "\n",
    "    self.embed = tf.keras.layers.Embedding(vocab_size, d_model)\n",
    "    self.pos_enc = positional_encoding(self.t, self.d_model)\n",
    "\n",
    "    self.dec_units = [DecoderUnit(d_model = d_model,\n",
    "                                  num_heads = num_heads,\n",
    "                                  dff = dff,\n",
    "                                  rate = rate,\n",
    "                                  kernels = kernels) for _ in range(num_layers)]\n",
    "\n",
    "    self.drop = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, enc_out, training, fut_mask, pad_mask):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    x = self.embed(x)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_enc[:, :seq_len, :]\n",
    "\n",
    "    x = self.drop(x, training = training)\n",
    "\n",
    "    for dec in self.dec_units:\n",
    "      x = dec(x, enc_out, training, fut_mask, pad_mask)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "f3IXemu4POuR"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, num_layers, t, d_model, num_heads, dff, input_vocab_size, output_vocab_size, rate = .1, kernels = [\"1d1\", \"3d1\", \"5d1\", \"7d1\"]):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.enc = Encoder(num_layers = num_layers,\n",
    "                       t = t,\n",
    "                       d_model = d_model,\n",
    "                       num_heads = num_heads,\n",
    "                       dff = dff,\n",
    "                       vocab_size = input_vocab_size,\n",
    "                       rate = rate,\n",
    "                       kernels = kernels)\n",
    "    self.dec = Decoder(num_layers = num_layers,\n",
    "                       t = t,\n",
    "                       d_model = d_model,\n",
    "                       num_heads = num_heads,\n",
    "                       dff = dff,\n",
    "                       vocab_size = output_vocab_size,\n",
    "                       rate = rate,\n",
    "                       kernels = kernels)\n",
    "    \n",
    "    self.linear = tf.keras.layers.Dense(output_vocab_size)\n",
    "\n",
    "  def call(self, inputs, training):\n",
    "    x, y = inputs\n",
    "\n",
    "    pad_mask = padding_mask(x)\n",
    "    fut_mask = future_mask(tf.shape(y)[1])\n",
    "    dec_pad_mask = padding_mask(y)\n",
    "    fut_mask = tf.maximum(dec_pad_mask, fut_mask)\n",
    "\n",
    "    enc_out = self.enc(x, training, pad_mask)\n",
    "\n",
    "    dec_out = self.dec(y, enc_out, training, fut_mask, pad_mask)\n",
    "\n",
    "    t_out = self.linear(dec_out)\n",
    "\n",
    "    return(t_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kHh2_9UIaaIW"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \n",
    "  def __init__(self, d_model, warmup_steps = 4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "  \n",
    "  def get_config(self):\n",
    "    config = {\"d_model\": self.d_model,\n",
    "              \"warmup_steps\": self.warmup_steps}\n",
    "    \n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZHkxwIVaehA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# custom training loop\n",
    "lr = CustomSchedule(d_model)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = \"none\")\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype = loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.keras.backend.mean(tf.reduce_sum(loss_) / tf.reduce_sum(mask))\n",
    "  # return tf.nn.compute_average_loss([loss_], global_batch_size = batch_size)\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "  accuracies = tf.equal(real, tf.argmax(pred, axis = 2))\n",
    "\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "  accuracies = tf.cast(accuracies, dtype = tf.float32)\n",
    "  mask = tf.cast(mask, dtype = tf.float32)\n",
    "  return tf.reduce_sum(accuracies) / tf.reduce_sum(mask)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name = \"train_loss\")\n",
    "train_accuracy = tf.keras.metrics.Mean(name = \"train_accuracy\")\n",
    "validation_loss = tf.keras.metrics.Mean(name = \"validation_loss\")\n",
    "validation_accuracy = tf.keras.metrics.Mean(name = \"validation_accuracy\")\n",
    "\n",
    "gpus = tf.config.list_logical_devices(\"GPU\")\n",
    "strategy = tf.distribute.MirroredStrategy(gpus)\n",
    "with strategy.scope():\n",
    "  model = Transformer(\n",
    "    num_layers = num_layers,\n",
    "    t = zh_max_len,\n",
    "    d_model = d_model,\n",
    "    num_heads = num_heads,\n",
    "    dff = dff,\n",
    "    input_vocab_size = zh_vocab_size,\n",
    "    output_vocab_size = en_vocab_size,\n",
    "    rate = dropout_rate,\n",
    "    kernels = kernels)\n",
    "  \n",
    "  optimizer = tf.keras.optimizers.Adam(lr, beta_1 = 0.9, beta_2 = 0.98, epsilon = 1e-9)\n",
    "  \n",
    "en_train_ds_pad = np.concatenate((en_train_ds, np.zeros((en_train_ds.shape[0], 1))), axis = 1)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((zh_train_ds.astype(np.int64), en_train_ds_pad.astype(np.int64)))\n",
    "train_batches = train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "train_batches = strategy.experimental_distribute_dataset(train_batches)\n",
    "\n",
    "en_val_ds_pad = np.concatenate((en_val_ds, np.zeros((en_val_ds.shape[0], 1))), axis = 1)\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((zh_val_ds.astype(np.int64), en_val_ds_pad.astype(np.int64)))\n",
    "validation_batches = validation_dataset.batch(batch_size // 8).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_step_signature = [tf.TensorSpec(shape = (None, None), dtype = tf.int64), tf.TensorSpec(shape = (None, None), dtype = tf.int64)]\n",
    "\n",
    "def train_step(x, y):\n",
    "  y_in = y[:, :-1]\n",
    "  y_out = y[:, 1:]\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = model([x, y_in], training = True)\n",
    "    loss = loss_function(y_out, predictions)\n",
    "    \n",
    "  train_accuracy(accuracy_function(y_out, predictions))\n",
    "\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "  \n",
    "  return loss\n",
    "  \n",
    "@tf.function\n",
    "def distributed_train_step(dist_x, dist_y):\n",
    "  single_loss = strategy.run(train_step, args = (dist_x, dist_y,))\n",
    "  return strategy.reduce(tf.distribute.ReduceOp.SUM, single_loss, axis = None)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  validation_loss.reset_states()\n",
    "  validation_accuracy.reset_states()\n",
    "\n",
    "  iterate = tqdm(enumerate(train_batches), total = -(zh_train_ds.shape[0] // -batch_size))\n",
    "  for (batch, (x, y)) in iterate:\n",
    "    batch_loss = distributed_train_step(x, y)\n",
    "    train_loss(batch_loss)\n",
    "    iterate.set_description(f\"loss: {train_loss.result():.2f} - accuracy: {train_accuracy.result():.4f}\")\n",
    "    \n",
    "  for (batch, (x, y)) in enumerate(validation_batches):\n",
    "    predictions = model([x, y[:, :-1]], training = False)\n",
    "    validation_loss(loss_function(y[:, 1:], predictions))\n",
    "    validation_accuracy(accuracy_function(y[:, 1:], predictions))\n",
    "    \n",
    "  print(f\"validation loss: {validation_loss.result():.4f} - validation accuracy: {validation_accuracy.result():.4f}\")\n",
    "  \n",
    "  if train_accuracy.result() >= target_acc:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training with keras.model.fit\n",
    "class accuracy_callback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs = {}):\n",
    "    if(logs.get(\"accuracy_function\") >= target_acc):\n",
    "      self.model.stop_training = True\n",
    "\n",
    "acc_call = accuracy_callback()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = \"none\")\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype = loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.keras.backend.mean(tf.reduce_sum(loss_) / tf.reduce_sum(mask))\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "  accuracies = tf.equal(real, tf.cast(tf.argmax(pred, axis = 2), tf.float32))\n",
    "\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "  accuracies = tf.cast(accuracies, dtype = tf.float32)\n",
    "  mask = tf.cast(mask, dtype = tf.float32)\n",
    "  return tf.keras.backend.mean(tf.reduce_sum(accuracies) / tf.reduce_sum(mask))\n",
    "\n",
    "en_train_ds_pad = np.concatenate((en_train_ds, np.zeros((en_train_ds.shape[0], 1))), axis = 1)\n",
    "en_dec_train_ds = en_train_ds_pad[:, 1:]\n",
    "en_train_ds = en_train_ds_pad[:, :-1]\n",
    "\n",
    "en_val_ds_pad = np.concatenate((en_val_ds, np.zeros((en_val_ds.shape[0], 1))), axis = 1)\n",
    "en_dec_val_ds = en_val_ds_pad[:, 1:]\n",
    "en_val_ds = en_val_ds_pad[:, :-1]\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "gpus = tf.config.list_logical_devices(\"GPU\")\n",
    "strategy = tf.distribute.MirroredStrategy(gpus)\n",
    "with strategy.scope():\n",
    "  model = Transformer(\n",
    "    num_layers = num_layers,\n",
    "    t = zh_max_len,\n",
    "    d_model = d_model,\n",
    "    num_heads = num_heads,\n",
    "    dff = dff,\n",
    "    input_vocab_size = zh_vocab_size,\n",
    "    output_vocab_size = en_vocab_size,\n",
    "    rate = dropout_rate,\n",
    "    kernels = kernels)\n",
    "\n",
    "  lr = CustomSchedule(d_model)\n",
    "  optimizer = tf.keras.optimizers.Adam(lr, beta_1 = 0.9, beta_2 = 0.98, epsilon = 1e-9)\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = loss_function, metrics = [accuracy_function])\n",
    "# history = model.fit([zh_train_ds, en_train_ds], en_dec_train_ds, batch_size = batch_size, epochs = epochs, callbacks = [acc_call])\n",
    "history = model.fit([zh_train_ds, en_train_ds], en_dec_train_ds, batch_size = batch_size, epochs = epochs, callbacks = [acc_call], validation_data = ([zh_val_ds, en_val_ds], en_dec_val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_4 (Encoder)         multiple                  48430080  \n",
      "                                                                 \n",
      " decoder_2 (Decoder)         multiple                  68895744  \n",
      "                                                                 \n",
      " dense_103 (Dense)           multiple                  15390000  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 132,715,824\n",
      "Trainable params: 132,715,824\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if graph:\n",
    "  loss = history.history[\"loss\"]\n",
    "  accuracy = history.history[\"accuracy_function\"]\n",
    "  val_loss = history.history[\"val_loss\"]\n",
    "  val_accuracy = history.history[\"val_accuracy_function\"]\n",
    "  timerange = range(len(loss))\n",
    "\n",
    "  fig,ax = plt.subplots()\n",
    "  train_loss_plot, = ax.plot(timerange, loss, color = \"blue\")\n",
    "  val_loss_plot, = ax.plot(timerange, val_loss, color = \"cyan\")\n",
    "  train_loss_plot.set_label(\"Train Loss\")\n",
    "  val_loss_plot.set_label(\"Validation Loss\")\n",
    "  ax.set_xlabel(\"Epoch\")\n",
    "  ax.set_ylabel(\"Loss\")\n",
    "  ax.legend(loc = \"upper left\")\n",
    "  ax2 = ax.twinx()\n",
    "  train_acc_plot, = ax2.plot(timerange, accuracy, color = \"purple\")\n",
    "  val_acc_plot, = ax2.plot(timerange, val_accuracy, color = \"pink\")\n",
    "  train_acc_plot.set_label(\"Train Accuracy\")\n",
    "  val_acc_plot.set_label(\"Validation Accuracy\")\n",
    "  ax2.set_ylabel(\"Accuracy\")\n",
    "  ax2.legend(loc = \"upper right\")\n",
    "  plt.title(\"Loss vs Accuracy\")\n",
    "  plt.savefig(f\"samples{train_samples}_dims{d_model}_date{datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model:\n",
    "  model.save(f\"model_{datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Testing and Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jieba_tok(zh):\n",
    "  cut = jieba.lcut(zh.numpy(), cut_all = False, HMM = True)\n",
    "  if cut[0] in zh_dictionary:  # Some samples have bad encoding, check here\n",
    "    zh_sentence = \" \".join(cut)\n",
    "    return [\"<SOS> \" + zh_sentence + \" <EOS>\"]\n",
    "\n",
    "sentence = \"这种恐惧是真实而内在的。忽视它的政治家们前途堪忧。\"\n",
    "sentence = zh_tokenize.predict([jieba_tok(tf.constant(sentence))])\n",
    "encoder_input = sentence\n",
    "\n",
    "start_end = en_tokenize.predict([\"<SOS> <EOS>\"])[0]\n",
    "start = start_end[0][tf.newaxis]\n",
    "end = start_end[1][tf.newaxis]\n",
    "\n",
    "output_array = tf.TensorArray(dtype = tf.int64, size = 0, dynamic_size = True)\n",
    "output_array = output_array.write(0, start)\n",
    "\n",
    "for i in range(zh_max_len):\n",
    "  output = tf.transpose(output_array.stack())\n",
    "  predictions = model([encoder_input, output], training = False)\n",
    "  predictions = predictions[:, -1:, :]\n",
    "  predicted_id = tf.argmax(predictions, axis=-1)\n",
    "  output_array = output_array.write(i + 1, predicted_id[0])\n",
    "\n",
    "  if predicted_id == end:\n",
    "    break\n",
    "\n",
    "output = tf.transpose(output_array.stack())\n",
    "translated = \" \".join([en_tokenize.layers[0].get_vocabulary()[x] for x in output[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sos the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_train_ds = en_train_ds.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[2]])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(model([tf.constant([zh_train_ds[0]]), tf.constant([[3]])], training = False), axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 200), dtype=int64, numpy=\n",
       "array([[    2,   670,    11,   195,     7, 19768,     7,   529,  2098,\n",
       "           15,    34,    30,  6489,     4,     4,     4,     4,     4,\n",
       "            4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "            4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "            4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "            4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "            4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "            4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "            4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "            4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "            4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "            4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "            4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "            4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "            4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "            4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "            4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "            4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "            4,     4, 22217,  3568,     4,     7,     7,     7,     7,\n",
       "            7,     7,     7,     7,     7,     7,     4,     4,     4,\n",
       "            4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "            4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
       "            4,     4]])>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(model([tf.constant([zh_train_ds[0]]), tf.constant([en_train_ds[0]])], training = False), axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    2,   670,    11,   195,     7, 19768,     7,   529,  2098,\n",
       "          15,    34,    30,  6489,     4,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_dec_train_ds[0].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 200, 512), dtype=float32, numpy=\n",
       "array([[[-3.4734507 ,  3.6488357 ,  0.39098012, ..., -1.7660774 ,\n",
       "          0.68327445,  2.0372803 ],\n",
       "        [ 1.7265517 , -0.7888653 ,  0.67978173, ..., -0.28295362,\n",
       "          0.21785867,  0.05945037],\n",
       "        [ 2.6306112 , -1.6056834 , -0.38916585, ..., -0.39674202,\n",
       "         -0.15986097, -0.8748788 ],\n",
       "        ...,\n",
       "        [ 0.11995114,  0.14242339, -0.5560821 , ..., -0.3273135 ,\n",
       "          1.4955416 , -1.668812  ],\n",
       "        [ 0.11226169,  0.13946927, -0.5594759 , ..., -0.34495303,\n",
       "          1.4877448 , -1.6698939 ],\n",
       "        [-0.04589487,  0.30989638, -0.4449291 , ..., -0.41543242,\n",
       "          1.5078495 , -1.5885388 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([zh_train_ds[0]])\n",
    "model.layers[0](x, training = False, mask = padding_mask(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 200, 512), dtype=float32, numpy=\n",
       "array([[[-3.3785877 ,  3.765343  ,  0.37646654, ..., -1.701465  ,\n",
       "          0.5321322 ,  2.0792649 ],\n",
       "        [ 1.5157515 , -0.49536717,  0.79236424, ..., -0.13220392,\n",
       "          0.14634545,  0.30558884],\n",
       "        [ 2.677649  , -1.6759564 , -0.17179795, ..., -0.24173526,\n",
       "         -0.13854988, -0.50096387],\n",
       "        ...,\n",
       "        [-0.41862807,  0.48642254, -0.53352046, ..., -0.3603158 ,\n",
       "          1.4703101 , -1.5124484 ],\n",
       "        [-0.28547883,  0.34364972, -0.51866335, ..., -0.3517639 ,\n",
       "          1.4697438 , -1.5535486 ],\n",
       "        [-0.37867805,  0.49029425, -0.48061806, ..., -0.45513225,\n",
       "          1.3955941 , -1.4502699 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([zh_train_ds[3000]])\n",
    "model.layers[0](x, training = False, mask = padding_mask(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ sacrebleu -t wmt17 -l en-de --echo src > wmt17.en-de.en\n",
    "$ sacrebleu -t wmt17 -l en-de -i output.detok.txt"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
